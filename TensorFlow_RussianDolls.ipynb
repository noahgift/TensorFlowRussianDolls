{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow-RussianDolls.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "1ilOvhjA3xS1",
        "WguU1NgEsCL6",
        "DskmJEsu8xdX",
        "QDDm6TsK34PC",
        "ItXfxkxvosLH",
        "NvoiEwiAWrWy",
        "Aa-KnZKcfvkV",
        "yVLSSAUViyiX",
        "W3G5sZ3yo-yK",
        "ggjuE4es7SDH"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noahgift/TensorFlowRussianDolls/blob/master/TensorFlow_RussianDolls.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "dRxWhH0g3tKF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# TensorFlow Russian Dolls\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "EggdJbEp6Pak",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![wikipedia_commons](https://upload.wikimedia.org/wikipedia/commons/thumb/0/0a/Russian_Dolls.jpg/640px-Russian_Dolls.jpg)\n",
        "\n",
        "[*source:  wikipedia*](https://upload.wikimedia.org/wikipedia/commons/thumb/0/0a/Russian_Dolls.jpg/640px-Russian_Dolls.jpg)"
      ]
    },
    {
      "metadata": {
        "id": "g5uaujBRJ7Z9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A *crash course* involving several layers of abstraction with [TensorFlow](https://www.tensorflow.org/)"
      ]
    },
    {
      "metadata": {
        "id": "1ilOvhjA3xS1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## TensorFlow"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "WguU1NgEsCL6"
      },
      "cell_type": "markdown",
      "source": [
        "### TensorFlow Hello World"
      ]
    },
    {
      "metadata": {
        "id": "oDpT_ks65v4J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "References\n",
        "\n",
        "*  [Official Hello World Example]( https://colab.research.google.com/notebooks/welcome.ipynb#scrollTo=oYZkU7ZN3CL0)\n",
        "*  Adds two matrices\n"
      ]
    },
    {
      "metadata": {
        "id": "5iX0wEVI6t49",
        "colab_type": "code",
        "outputId": "f0c90b85-309a-456e-bfba-9ade12b57e7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "input1 = tf.ones((2, 3))\n",
        "input2 = tf.reshape(tf.range(1, 7, dtype=tf.float32), (2, 3))\n",
        "\n",
        "print(\"Two Tensor Flow Matrices with shape:\")\n",
        "print(input1.shape)\n",
        "print(input2.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Two Tensor Flow Matrices with shape:\n",
            "(2, 3)\n",
            "(2, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "afyOLD6p5l3_",
        "colab_type": "code",
        "outputId": "de7ba70a-3bf3-4d2b-f25b-867674ad4857",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "output = input1 + input2\n",
        "with tf.Session():\n",
        "  result = output.eval()\n",
        "\n",
        "print(f\"Type of result:  {type(result)}\\n\")\n",
        "print(\"Result of addition of two Matrics:\")\n",
        "result\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type of result:  <class 'numpy.ndarray'>\n",
            "\n",
            "Result of addition of two Matrics:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2., 3., 4.],\n",
              "       [5., 6., 7.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "DskmJEsu8xdX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Enable TPU Support in Colab"
      ]
    },
    {
      "metadata": {
        "id": "rrWQ83Cd81dN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![TPU](https://user-images.githubusercontent.com/58792/53053297-d14f2400-3455-11e9-836d-3857de1f4337.png)"
      ]
    },
    {
      "metadata": {
        "id": "QDDm6TsK34PC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Keras"
      ]
    },
    {
      "metadata": {
        "id": "ItXfxkxvosLH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Text classification with movie reviews (Project)"
      ]
    },
    {
      "metadata": {
        "id": "hKY4XMc9o8iB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*Modified based on this tutorial: * https://research.google.com/seedbank/seed/classify_movie_reviews_using_tfkeras\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/keras/basic_text_classification\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/keras/basic_text_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/basic_text_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "metadata": {
        "id": "Eg62Pmz3o83v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "This notebook classifies movie reviews as *positive* or *negative* using the text of the review. This is an example of *binary*—or two-class—classification, an important and widely applicable kind of machine learning problem. \n",
        "\n",
        "We'll use the [IMDB dataset](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/imdb) that contains the text of 50,000 movie reviews from the [Internet Movie Database](https://www.imdb.com/). These are split into 25,000 reviews for training and 25,000 reviews for testing. The training and testing sets are *balanced*, meaning they contain an equal number of positive and negative reviews. \n",
        "\n",
        "This notebook uses [tf.keras](https://www.tensorflow.org/guide/keras), a high-level API to build and train models in TensorFlow. For a more advanced text classification tutorial using `tf.keras`, see the [MLCC Text Classification Guide](https://developers.google.com/machine-learning/guides/text-classification/)."
      ]
    },
    {
      "metadata": {
        "id": "2ew7HTbPpCJH",
        "colab_type": "code",
        "outputId": "2aba4140-9619-4438-8efd-bc8ae9b77529",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.0-rc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zZ8c25ug_FTf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Ingest"
      ]
    },
    {
      "metadata": {
        "id": "iAsKG535pHep",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Download the IMDB dataset\n",
        "\n",
        "The IMDB dataset comes packaged with TensorFlow. It has already been preprocessed such that the reviews (sequences of words) have been converted to sequences of integers, where each integer represents a specific word in a dictionary.\n",
        "\n",
        "The following code downloads the IMDB dataset to your machine (or uses a cached copy if you've already downloaded it):"
      ]
    },
    {
      "metadata": {
        "id": "zXXx5Oc3pOmN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "imdb = keras.datasets.imdb\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "odr-KlzO-lkL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The argument `num_words=10000` keeps the top 10,000 most frequently occurring words in the training data. The rare words are discarded to keep the size of the data manageable."
      ]
    },
    {
      "metadata": {
        "id": "l50X3GfjpU4r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Explore the data (EDA)\n",
        "\n",
        "Let's take a moment to understand the format of the data. The dataset comes preprocessed: each example is an array of integers representing the words of the movie review. Each label is an integer value of either 0 or 1, where 0 is a negative review, and 1 is a positive review."
      ]
    },
    {
      "metadata": {
        "id": "y8qCnve_-lkO",
        "colab_type": "code",
        "outputId": "93ecfc37-3aea-411c-e047-833149f775b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Training entries: {}, labels: {}\".format(len(train_data), len(train_labels)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training entries: 25000, labels: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RnKvHWW4-lkW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The text of reviews have been converted to integers, where each integer represents a specific word in a dictionary. Here's what the first review looks like:"
      ]
    },
    {
      "metadata": {
        "id": "QtTS4kpEpjbi",
        "colab_type": "code",
        "outputId": "5326cadb-a7bc-443d-c0f2-eac74b325007",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "print(train_data[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hIE4l_72x7DP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Movie reviews may be different lengths. The below code shows the number of words in the first and second reviews. Since inputs to a neural network must be the same length, we'll need to resolve this later."
      ]
    },
    {
      "metadata": {
        "id": "X-6Ii9Pfx6Nr",
        "colab_type": "code",
        "outputId": "f1759641-c8c9-4697-b239-55f7c5661fca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "len(train_data[0]), len(train_data[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(218, 189)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "4wJg2FiYpuoX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Convert the integers back to words\n",
        "\n",
        "It may be useful to know how to convert integers back to text. Here, we'll create a helper function to query a dictionary object that contains the integer to string mapping:"
      ]
    },
    {
      "metadata": {
        "id": "tr5s_1alpzop",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# A dictionary mapping words to an integer index\n",
        "word_index = imdb.get_word_index()\n",
        "\n",
        "# The first indices are reserved\n",
        "word_index = {k:(v+3) for k,v in word_index.items()} \n",
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START>\"] = 1\n",
        "word_index[\"<UNK>\"] = 2  # unknown\n",
        "word_index[\"<UNUSED>\"] = 3\n",
        "\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "def decode_review(text):\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U3CNRvEZVppl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we can use the `decode_review` function to display the text for the first review:"
      ]
    },
    {
      "metadata": {
        "id": "s_OqxmH6-lkn",
        "colab_type": "code",
        "outputId": "f3bae642-91e0-45a8-9c84-5b9dfba0d7bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "decode_review(train_data[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "lFP_XKVRp4_S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Prepare the data\n",
        "\n",
        "The reviews—the arrays of integers—must be converted to tensors before fed into the neural network. This conversion can be done a couple of ways:\n",
        "\n",
        "* Convert the arrays into vectors of 0s and 1s indicating word occurrence, similar to a one-hot encoding. For example, the sequence  [3, 5] would become a 10,000-dimensional vector that is all zeros except for indices 3 and 5, which are ones. Then, make this the first layer in our network—a Dense layer—that can handle floating point vector data. This approach is memory intensive, though, requiring a `num_words * num_reviews` size matrix.\n",
        "\n",
        "* Alternatively, we can pad the arrays so they all have the same length, then create an integer tensor of shape `max_length * num_reviews`. We can use an embedding layer capable of handling this shape as the first layer in our network.\n",
        "\n",
        "In this tutorial, we will use the second approach. \n",
        "\n",
        "Since the movie reviews must be the same length, we will use the [pad_sequences](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences) function to standardize the lengths:"
      ]
    },
    {
      "metadata": {
        "id": "2jQv-omsHurp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data = keras.preprocessing.sequence.pad_sequences(train_data,\n",
        "                                                        value=word_index[\"<PAD>\"],\n",
        "                                                        padding='post',\n",
        "                                                        maxlen=256)\n",
        "\n",
        "test_data = keras.preprocessing.sequence.pad_sequences(test_data,\n",
        "                                                       value=word_index[\"<PAD>\"],\n",
        "                                                       padding='post',\n",
        "                                                       maxlen=256)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VO5MBpyQdipD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's look at the length of the examples now:"
      ]
    },
    {
      "metadata": {
        "id": "USSSBnkE-lky",
        "colab_type": "code",
        "outputId": "73c95e4e-a3a8-48f8-f6d4-4e8a53900208",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "len(train_data[0]), len(train_data[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(256, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "QJoxZGyfjT5V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "And inspect the (now padded) first review:"
      ]
    },
    {
      "metadata": {
        "id": "TG8X9cqi-lk9",
        "colab_type": "code",
        "outputId": "875c097c-5e49-49ed-bdba-5a1566dd9c94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "print(train_data[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   1   14   22   16   43  530  973 1622 1385   65  458 4468   66 3941\n",
            "    4  173   36  256    5   25  100   43  838  112   50  670    2    9\n",
            "   35  480  284    5  150    4  172  112  167    2  336  385   39    4\n",
            "  172 4536 1111   17  546   38   13  447    4  192   50   16    6  147\n",
            " 2025   19   14   22    4 1920 4613  469    4   22   71   87   12   16\n",
            "   43  530   38   76   15   13 1247    4   22   17  515   17   12   16\n",
            "  626   18    2    5   62  386   12    8  316    8  106    5    4 2223\n",
            " 5244   16  480   66 3785   33    4  130   12   16   38  619    5   25\n",
            "  124   51   36  135   48   25 1415   33    6   22   12  215   28   77\n",
            "   52    5   14  407   16   82    2    8    4  107  117 5952   15  256\n",
            "    4    2    7 3766    5  723   36   71   43  530  476   26  400  317\n",
            "   46    7    4    2 1029   13  104   88    4  381   15  297   98   32\n",
            " 2071   56   26  141    6  194 7486   18    4  226   22   21  134  476\n",
            "   26  480    5  144   30 5535   18   51   36   28  224   92   25  104\n",
            "    4  226   65   16   38 1334   88   12   16  283    5   16 4472  113\n",
            "  103   32   15   16 5345   19  178   32    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LLC02j2g-llC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Modeling\n",
        "\n",
        "The neural network is created by stacking layers—this requires two main architectural decisions:\n",
        "\n",
        "* How many layers to use in the model?\n",
        "* How many *hidden units* to use for each layer?\n",
        "\n",
        "In this example, the input data consists of an array of word-indices. The labels to predict are either 0 or 1. Let's build a model for this problem:"
      ]
    },
    {
      "metadata": {
        "id": "xpKOoWgu-llD",
        "colab_type": "code",
        "outputId": "98611538-0b48-4473-8338-b1e77e03adde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "# input shape is the vocabulary count used for the movie reviews (10,000 words)\n",
        "vocab_size = 10000\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(vocab_size, 16))\n",
        "model.add(keras.layers.GlobalAveragePooling1D())\n",
        "model.add(keras.layers.Dense(16, activation=tf.nn.relu))\n",
        "model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 16)          160000    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 160,289\n",
            "Trainable params: 160,289\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6PbKQ6mucuKL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The layers are stacked sequentially to build the classifier:\n",
        "\n",
        "1. The first layer is an `Embedding` layer. This layer takes the integer-encoded vocabulary and looks up the embedding vector for each word-index. These vectors are learned as the model trains. The vectors add a dimension to the output array. The resulting dimensions are: `(batch, sequence, embedding)`.\n",
        "2. Next, a `GlobalAveragePooling1D` layer returns a fixed-length output vector for each example by averaging over the sequence dimension. This allows the model to handle input of variable length, in the simplest way possible.\n",
        "3. This fixed-length output vector is piped through a fully-connected (`Dense`) layer with 16 hidden units.\n",
        "4. The last layer is densely connected with a single output node. Using the `sigmoid` activation function, this value is a float between 0 and 1, representing a probability, or confidence level."
      ]
    },
    {
      "metadata": {
        "id": "Bn9ukmAb_pKE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Hidden units"
      ]
    },
    {
      "metadata": {
        "id": "0XMwnDOp-llH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "The above model has two intermediate or \"hidden\" layers, between the input and output. The number of outputs (units, nodes, or neurons) is the dimension of the representational space for the layer. In other words, the amount of freedom the network is allowed when learning an internal representation.\n",
        "\n",
        "If a model has more hidden units (a higher-dimensional representation space), and/or more layers, then the network can learn more complex representations. However, it makes the network more computationally expensive and may lead to learning unwanted patterns—patterns that improve performance on training data but not on the test data. This is called *overfitting*, and we'll explore it later."
      ]
    },
    {
      "metadata": {
        "id": "L4EqVWg4-llM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Loss function and optimizer\n",
        "\n",
        "A model needs a loss function and an optimizer for training. Since this is a binary classification problem and the model outputs a probability (a single-unit layer with a sigmoid activation), we'll use the `binary_crossentropy` loss function. \n",
        "\n",
        "This isn't the only choice for a loss function, you could, for instance, choose `mean_squared_error`. But, generally, `binary_crossentropy` is better for dealing with probabilities—it measures the \"distance\" between probability distributions, or in our case, between the ground-truth distribution and the predictions.\n",
        "\n",
        "Later, when we are exploring regression problems (say, to predict the price of a house), we will see how to use another loss function called mean squared error.\n",
        "\n",
        "Now, configure the model to use an optimizer and a loss function:"
      ]
    },
    {
      "metadata": {
        "id": "Mr0GP-cQ-llN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hCWYwkug-llQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Create a validation set\n",
        "\n",
        "When training, we want to check the accuracy of the model on data it hasn't seen before. Create a *validation set* by setting apart 10,000 examples from the original training data. (Why not use the testing set now? Our goal is to develop and tune our model using only the training data, then use the test data just once to evaluate our accuracy)."
      ]
    },
    {
      "metadata": {
        "id": "-NpcXY9--llS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_val = train_data[:10000]\n",
        "partial_x_train = train_data[10000:]\n",
        "\n",
        "y_val = train_labels[:10000]\n",
        "partial_y_train = train_labels[10000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "35jv_fzP-llU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Train the model\n",
        "\n",
        "Train the model for 40 epochs in mini-batches of 512 samples. This is 40 iterations over all samples in the `x_train` and `y_train` tensors. While training, monitor the model's loss and accuracy on the 10,000 samples from the validation set:"
      ]
    },
    {
      "metadata": {
        "id": "tXSGrjWZ-llW",
        "colab_type": "code",
        "outputId": "362eb02e-70f6-4b58-9216-9d9fecd81308",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=40,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15000 samples, validate on 10000 samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/40\n",
            "15000/15000 [==============================] - 1s 72us/sample - loss: 0.6919 - acc: 0.5917 - val_loss: 0.6899 - val_acc: 0.6604\n",
            "Epoch 2/40\n",
            "15000/15000 [==============================] - 1s 56us/sample - loss: 0.6863 - acc: 0.7150 - val_loss: 0.6825 - val_acc: 0.7219\n",
            "Epoch 3/40\n",
            "15000/15000 [==============================] - 1s 54us/sample - loss: 0.6751 - acc: 0.7439 - val_loss: 0.6688 - val_acc: 0.7506\n",
            "Epoch 4/40\n",
            "15000/15000 [==============================] - 1s 56us/sample - loss: 0.6560 - acc: 0.7493 - val_loss: 0.6471 - val_acc: 0.7631\n",
            "Epoch 5/40\n",
            "15000/15000 [==============================] - 1s 56us/sample - loss: 0.6280 - acc: 0.7817 - val_loss: 0.6177 - val_acc: 0.7795\n",
            "Epoch 6/40\n",
            "15000/15000 [==============================] - 1s 55us/sample - loss: 0.5919 - acc: 0.8043 - val_loss: 0.5826 - val_acc: 0.7924\n",
            "Epoch 7/40\n",
            "15000/15000 [==============================] - 1s 56us/sample - loss: 0.5504 - acc: 0.8190 - val_loss: 0.5429 - val_acc: 0.8139\n",
            "Epoch 8/40\n",
            "15000/15000 [==============================] - 1s 55us/sample - loss: 0.5072 - acc: 0.8391 - val_loss: 0.5044 - val_acc: 0.8268\n",
            "Epoch 9/40\n",
            "15000/15000 [==============================] - 1s 53us/sample - loss: 0.4644 - acc: 0.8532 - val_loss: 0.4665 - val_acc: 0.8387\n",
            "Epoch 10/40\n",
            "15000/15000 [==============================] - 1s 54us/sample - loss: 0.4240 - acc: 0.8665 - val_loss: 0.4335 - val_acc: 0.8454\n",
            "Epoch 11/40\n",
            "15000/15000 [==============================] - 1s 54us/sample - loss: 0.3886 - acc: 0.8749 - val_loss: 0.4053 - val_acc: 0.8551\n",
            "Epoch 12/40\n",
            "15000/15000 [==============================] - 1s 53us/sample - loss: 0.3582 - acc: 0.8842 - val_loss: 0.3834 - val_acc: 0.8579\n",
            "Epoch 13/40\n",
            "15000/15000 [==============================] - 1s 54us/sample - loss: 0.3333 - acc: 0.8911 - val_loss: 0.3637 - val_acc: 0.8651\n",
            "Epoch 14/40\n",
            "15000/15000 [==============================] - 1s 54us/sample - loss: 0.3110 - acc: 0.8959 - val_loss: 0.3494 - val_acc: 0.8689\n",
            "Epoch 15/40\n",
            "15000/15000 [==============================] - 1s 54us/sample - loss: 0.2925 - acc: 0.9006 - val_loss: 0.3371 - val_acc: 0.8720\n",
            "Epoch 16/40\n",
            "15000/15000 [==============================] - 1s 54us/sample - loss: 0.2761 - acc: 0.9060 - val_loss: 0.3273 - val_acc: 0.8733\n",
            "Epoch 17/40\n",
            "15000/15000 [==============================] - 1s 55us/sample - loss: 0.2611 - acc: 0.9108 - val_loss: 0.3190 - val_acc: 0.8760\n",
            "Epoch 18/40\n",
            "15000/15000 [==============================] - 1s 54us/sample - loss: 0.2479 - acc: 0.9153 - val_loss: 0.3117 - val_acc: 0.8788\n",
            "Epoch 19/40\n",
            "15000/15000 [==============================] - 1s 53us/sample - loss: 0.2361 - acc: 0.9188 - val_loss: 0.3058 - val_acc: 0.8803\n",
            "Epoch 20/40\n",
            "15000/15000 [==============================] - 1s 54us/sample - loss: 0.2255 - acc: 0.9225 - val_loss: 0.3017 - val_acc: 0.8802\n",
            "Epoch 21/40\n",
            "15000/15000 [==============================] - 1s 54us/sample - loss: 0.2148 - acc: 0.9274 - val_loss: 0.2981 - val_acc: 0.8805\n",
            "Epoch 22/40\n",
            "15000/15000 [==============================] - 1s 54us/sample - loss: 0.2058 - acc: 0.9294 - val_loss: 0.2943 - val_acc: 0.8834\n",
            "Epoch 23/40\n",
            "15000/15000 [==============================] - 1s 53us/sample - loss: 0.1968 - acc: 0.9332 - val_loss: 0.2925 - val_acc: 0.8826\n",
            "Epoch 24/40\n",
            "15000/15000 [==============================] - 1s 52us/sample - loss: 0.1889 - acc: 0.9370 - val_loss: 0.2905 - val_acc: 0.8841\n",
            "Epoch 25/40\n",
            "15000/15000 [==============================] - 1s 53us/sample - loss: 0.1809 - acc: 0.9409 - val_loss: 0.2881 - val_acc: 0.8838\n",
            "Epoch 26/40\n",
            "15000/15000 [==============================] - 1s 53us/sample - loss: 0.1739 - acc: 0.9435 - val_loss: 0.2882 - val_acc: 0.8840\n",
            "Epoch 27/40\n",
            "15000/15000 [==============================] - 1s 52us/sample - loss: 0.1671 - acc: 0.9461 - val_loss: 0.2870 - val_acc: 0.8838\n",
            "Epoch 28/40\n",
            "15000/15000 [==============================] - 1s 53us/sample - loss: 0.1606 - acc: 0.9496 - val_loss: 0.2870 - val_acc: 0.8858\n",
            "Epoch 29/40\n",
            "15000/15000 [==============================] - 1s 56us/sample - loss: 0.1550 - acc: 0.9522 - val_loss: 0.2876 - val_acc: 0.8835\n",
            "Epoch 30/40\n",
            "15000/15000 [==============================] - 1s 56us/sample - loss: 0.1492 - acc: 0.9537 - val_loss: 0.2866 - val_acc: 0.8856\n",
            "Epoch 31/40\n",
            "15000/15000 [==============================] - 1s 58us/sample - loss: 0.1431 - acc: 0.9574 - val_loss: 0.2871 - val_acc: 0.8859\n",
            "Epoch 32/40\n",
            "15000/15000 [==============================] - 1s 59us/sample - loss: 0.1378 - acc: 0.9593 - val_loss: 0.2880 - val_acc: 0.8855\n",
            "Epoch 33/40\n",
            "15000/15000 [==============================] - 1s 57us/sample - loss: 0.1325 - acc: 0.9603 - val_loss: 0.2896 - val_acc: 0.8860\n",
            "Epoch 34/40\n",
            "15000/15000 [==============================] - 1s 56us/sample - loss: 0.1279 - acc: 0.9628 - val_loss: 0.2911 - val_acc: 0.8852\n",
            "Epoch 35/40\n",
            "15000/15000 [==============================] - 1s 57us/sample - loss: 0.1237 - acc: 0.9633 - val_loss: 0.2926 - val_acc: 0.8864\n",
            "Epoch 36/40\n",
            "15000/15000 [==============================] - 1s 53us/sample - loss: 0.1189 - acc: 0.9665 - val_loss: 0.2941 - val_acc: 0.8857\n",
            "Epoch 37/40\n",
            "15000/15000 [==============================] - 1s 54us/sample - loss: 0.1144 - acc: 0.9679 - val_loss: 0.2963 - val_acc: 0.8857\n",
            "Epoch 38/40\n",
            "15000/15000 [==============================] - 1s 55us/sample - loss: 0.1103 - acc: 0.9695 - val_loss: 0.2992 - val_acc: 0.8843\n",
            "Epoch 39/40\n",
            "15000/15000 [==============================] - 1s 57us/sample - loss: 0.1071 - acc: 0.9703 - val_loss: 0.3021 - val_acc: 0.8836\n",
            "Epoch 40/40\n",
            "15000/15000 [==============================] - 1s 55us/sample - loss: 0.1028 - acc: 0.9725 - val_loss: 0.3042 - val_acc: 0.8844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9EEGuDVuzb5r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Evaluate the model\n",
        "\n",
        "And let's see how the model performs. Two values will be returned. Loss (a number which represents our error, lower values are better), and accuracy."
      ]
    },
    {
      "metadata": {
        "id": "zOMKywn4zReN",
        "colab_type": "code",
        "outputId": "9fea7e2e-b64b-492e-8464-b402615260f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "results = model.evaluate(test_data, test_labels)\n",
        "\n",
        "print(results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 1s 39us/sample - loss: 0.3236 - acc: 0.8720\n",
            "[0.32361660490989685, 0.872]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "z1iEXVTR0Z2t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This fairly naive approach achieves an accuracy of about 87%. With more advanced approaches, the model should get closer to 95%."
      ]
    },
    {
      "metadata": {
        "id": "5KggXVeL-llZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Create a graph of accuracy and loss over time\n",
        "\n",
        "`model.fit()` returns a `History` object that contains a dictionary with everything that happened during training:"
      ]
    },
    {
      "metadata": {
        "id": "VcvSXvhp-llb",
        "colab_type": "code",
        "outputId": "989173d6-eb8f-4394-ee87-1397fd4d31db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "history_dict = history.history\n",
        "history_dict.keys()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "nRKsqL40-lle",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "There are four entries: one for each monitored metric during training and validation. We can use these to plot the training and validation loss for comparison, as well as the training and validation accuracy:"
      ]
    },
    {
      "metadata": {
        "id": "nGoYf2Js-lle",
        "colab_type": "code",
        "outputId": "5e32ae1b-4b11-4ce9-e0bf-1734969507d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history_dict['acc']\n",
        "val_acc = history_dict['val_acc']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# \"bo\" is for \"blue dot\"\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "# b is for \"solid blue line\"\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJCkwhrckSYH5AcfTkWs5vCG/AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "6hXx-xOv-llh",
        "colab_type": "code",
        "outputId": "02ce5d01-233f-4194-b399-068368f0ad83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "plt.clf()   # clear figure\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFnCAYAAAC/5tBZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "oFEmZ5zq-llk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "In this plot, the dots represent the training loss and accuracy, and the solid lines are the validation loss and accuracy.\n",
        "\n",
        "Notice the training loss *decreases* with each epoch and the training accuracy *increases* with each epoch. This is expected when using a gradient descent optimization—it should minimize the desired quantity on every iteration.\n",
        "\n",
        "This isn't the case for the validation loss and accuracy—they seem to peak after about twenty epochs. This is an example of overfitting: the model performs better on the training data than it does on data it has never seen before. After this point, the model over-optimizes and learns representations *specific* to the training data that do not *generalize* to test data.\n",
        "\n",
        "For this particular case, we could prevent overfitting by simply stopping the training after twenty or so epochs. Later, you'll see how to do this automatically with a callback."
      ]
    },
    {
      "metadata": {
        "id": "NvoiEwiAWrWy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Ludwig (Open Source AutoML)"
      ]
    },
    {
      "metadata": {
        "id": "jbnbFKcTXNOn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Github Project URL**:  https://uber.github.io/ludwig/\n",
        "\n",
        "![alt text](https://user-images.githubusercontent.com/58792/52920000-f78d8c00-32bc-11e9-8e5e-adf53f1b8a37.png)"
      ]
    },
    {
      "metadata": {
        "id": "Aa-KnZKcfvkV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Install Ludwig"
      ]
    },
    {
      "metadata": {
        "id": "Q3FrtesdfyV9",
        "colab_type": "code",
        "outputId": "1db2fd0d-8904-489e-ac1f-70bc70c9704a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 925
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install --upgrade numpy #must restart colab runtime\n",
        "!pip install --upgrade scikit-image\n",
        "!pip install -q ludwig\n",
        "!python -m spacy download en "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: numpy in /usr/local/lib/python3.6/dist-packages (1.16.1)\n",
            "Collecting scikit-image\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/06/d560630eb9e36d90d69fe57d9ff762d8f501664ce478b8a0ae132b3c3008/scikit_image-0.14.2-cp36-cp36m-manylinux1_x86_64.whl (25.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 25.3MB 1.9MB/s \n",
            "\u001b[?25hCollecting pillow>=4.3.0 (from scikit-image)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/5e/e91792f198bbc5a0d7d3055ad552bc4062942d27eaf75c3e2783cf64eae5/Pillow-5.4.1-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 18.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (3.0.2)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.11.0)\n",
            "Requirement already satisfied, skipping upgrade: cloudpickle>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (0.6.1)\n",
            "Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: networkx>=1.8 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.2)\n",
            "Collecting dask[array]>=1.0.0 (from scikit-image)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/2b/cf9e5477bec3bd3b4687719876ea38e9d8c9dc9d3526365c74e836e6a650/dask-1.1.1-py2.py3-none-any.whl (701kB)\n",
            "\u001b[K    100% |████████████████████████████████| 706kB 25.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy>=0.17.0->scikit-image) (1.16.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->scikit-image) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->scikit-image) (2.3.1)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->scikit-image) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->scikit-image) (2.5.3)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=1.8->scikit-image) (4.3.2)\n",
            "Requirement already satisfied, skipping upgrade: toolz>=0.7.3; extra == \"array\" in /usr/local/lib/python3.6/dist-packages (from dask[array]>=1.0.0->scikit-image) (0.9.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.0.0->scikit-image) (40.8.0)\n",
            "\u001b[31mfeaturetools 0.4.1 has requirement pandas>=0.23.0, but you'll have pandas 0.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31malbumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.8 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pillow, dask, scikit-image\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "  Found existing installation: dask 0.20.2\n",
            "    Uninstalling dask-0.20.2:\n",
            "      Successfully uninstalled dask-0.20.2\n",
            "  Found existing installation: scikit-image 0.13.1\n",
            "    Uninstalling scikit-image-0.13.1:\n",
            "      Successfully uninstalled scikit-image-0.13.1\n",
            "Successfully installed dask-1.1.1 pillow-5.4.1 scikit-image-0.14.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "\n",
            "\u001b[93m    Linking successful\u001b[0m\n",
            "    /usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "    /usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "\n",
            "    You can now load the model via spacy.load('en')\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yVLSSAUViyiX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Basic Ideas"
      ]
    },
    {
      "metadata": {
        "id": "qHaRqAN5i1iV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* **Training Models**\n",
        "* **Prediction (Inference)**\n",
        "* **Datatypes**\n",
        " - binary\n",
        " - numerical\n",
        " - category\n",
        " - set\n",
        " - bag\n",
        " - sequence\n",
        " - text\n",
        " - timeseries\n",
        " - image\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "W3G5sZ3yo-yK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Classification of Book Title Categories (Project)"
      ]
    },
    {
      "metadata": {
        "id": "aIbXYrxU8ySd",
        "colab_type": "code",
        "outputId": "241c61f9-ad81-4c4d-82dd-42bef0502fdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/uchidalab/book-dataset/master/Task1/book30-listing-train.csv\n",
        "!wget https://raw.githubusercontent.com/noahgift/recommendations/master/model_definition.yaml"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-02-18 02:44:21--  https://raw.githubusercontent.com/uchidalab/book-dataset/master/Task1/book30-listing-train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9728786 (9.3M) [text/plain]\n",
            "Saving to: ‘book30-listing-train.csv.3’\n",
            "\n",
            "book30-listing-trai 100%[===================>]   9.28M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-02-18 02:44:23 (64.4 MB/s) - ‘book30-listing-train.csv.3’ saved [9728786/9728786]\n",
            "\n",
            "--2019-02-18 02:44:24--  https://raw.githubusercontent.com/noahgift/recommendations/master/model_definition.yaml\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 180 [text/plain]\n",
            "Saving to: ‘model_definition.yaml.2’\n",
            "\n",
            "model_definition.ya 100%[===================>]     180  --.-KB/s    in 0s      \n",
            "\n",
            "2019-02-18 02:44:25 (34.7 MB/s) - ‘model_definition.yaml.2’ saved [180/180]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "v-w5Zkzcumoi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Ingest"
      ]
    },
    {
      "metadata": {
        "id": "Ef8dbaV4tHrz",
        "colab_type": "code",
        "outputId": "e7bbaff9-edcf-43df-f142-f8e5e916338f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"https://media.githubusercontent.com/media/noahgift/recommendations/master/data/book30-listing-train-with-headers.csv\")\n",
        "df = df.drop(\"Unnamed: 0\", axis=1)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ASIN</th>\n",
              "      <th>FILENAME</th>\n",
              "      <th>IMAGE URL</th>\n",
              "      <th>TITLE</th>\n",
              "      <th>AUTHOR</th>\n",
              "      <th>CATEGORYID</th>\n",
              "      <th>CATEGORY</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1404803335</td>\n",
              "      <td>1404803335.jpg</td>\n",
              "      <td>http://ecx.images-amazon.com/images/I/51UJnL3T...</td>\n",
              "      <td>Magnets: Pulling Together, Pushing Apart (Amaz...</td>\n",
              "      <td>Natalie M. Rosinsky</td>\n",
              "      <td>4</td>\n",
              "      <td>Children's Books</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1446276082</td>\n",
              "      <td>1446276082.jpg</td>\n",
              "      <td>http://ecx.images-amazon.com/images/I/51MGUKhk...</td>\n",
              "      <td>Energy Security (SAGE Library of International...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10</td>\n",
              "      <td>Engineering &amp; Transportation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1491522666</td>\n",
              "      <td>1491522666.jpg</td>\n",
              "      <td>http://ecx.images-amazon.com/images/I/51qKvjsi...</td>\n",
              "      <td>An Amish Gathering: Life in Lancaster County</td>\n",
              "      <td>Beth Wiseman</td>\n",
              "      <td>9</td>\n",
              "      <td>Christian Books &amp; Bibles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>970096410</td>\n",
              "      <td>0970096410.jpg</td>\n",
              "      <td>http://ecx.images-amazon.com/images/I/51qoUENb...</td>\n",
              "      <td>City of Rocks Idaho: A Climber's Guide (Region...</td>\n",
              "      <td>Dave Bingham</td>\n",
              "      <td>26</td>\n",
              "      <td>Sports &amp; Outdoors</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8436808053</td>\n",
              "      <td>8436808053.jpg</td>\n",
              "      <td>http://ecx.images-amazon.com/images/I/41aDW5pz...</td>\n",
              "      <td>Como vencer el insomnio. Tecnicas, reglas y co...</td>\n",
              "      <td>Choliz Montanes</td>\n",
              "      <td>11</td>\n",
              "      <td>Health, Fitness &amp; Dieting</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         ASIN        FILENAME  \\\n",
              "0  1404803335  1404803335.jpg   \n",
              "1  1446276082  1446276082.jpg   \n",
              "2  1491522666  1491522666.jpg   \n",
              "3   970096410  0970096410.jpg   \n",
              "4  8436808053  8436808053.jpg   \n",
              "\n",
              "                                           IMAGE URL  \\\n",
              "0  http://ecx.images-amazon.com/images/I/51UJnL3T...   \n",
              "1  http://ecx.images-amazon.com/images/I/51MGUKhk...   \n",
              "2  http://ecx.images-amazon.com/images/I/51qKvjsi...   \n",
              "3  http://ecx.images-amazon.com/images/I/51qoUENb...   \n",
              "4  http://ecx.images-amazon.com/images/I/41aDW5pz...   \n",
              "\n",
              "                                               TITLE               AUTHOR  \\\n",
              "0  Magnets: Pulling Together, Pushing Apart (Amaz...  Natalie M. Rosinsky   \n",
              "1  Energy Security (SAGE Library of International...                  NaN   \n",
              "2       An Amish Gathering: Life in Lancaster County         Beth Wiseman   \n",
              "3  City of Rocks Idaho: A Climber's Guide (Region...         Dave Bingham   \n",
              "4  Como vencer el insomnio. Tecnicas, reglas y co...      Choliz Montanes   \n",
              "\n",
              "   CATEGORYID                      CATEGORY  \n",
              "0           4              Children's Books  \n",
              "1          10  Engineering & Transportation  \n",
              "2           9      Christian Books & Bibles  \n",
              "3          26             Sports & Outdoors  \n",
              "4          11     Health, Fitness & Dieting  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "efw0icqJ_0Bq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df.to_csv(\"book30-listing-train-with-headers.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wR_L2OPkuqH4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### EDA"
      ]
    },
    {
      "metadata": {
        "id": "IUGz5U5duj-D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Columns**"
      ]
    },
    {
      "metadata": {
        "id": "KVYJIiwHuhiT",
        "colab_type": "code",
        "outputId": "c5a39f2f-e99f-4514-8bb8-ebe7c4eee1b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['ASIN', 'FILENAME', 'IMAGE URL', 'TITLE', 'AUTHOR', 'CATEGORYID',\n",
              "       'CATEGORY'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "id": "ir0Viy2zuyr1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Shape**"
      ]
    },
    {
      "metadata": {
        "id": "-kaJsKyruyAl",
        "colab_type": "code",
        "outputId": "f0e37663-1297-49c0-e000-ec0af6665d43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(51299, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "JJNSA3n0u3Zf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Training w/Ludwig"
      ]
    },
    {
      "metadata": {
        "id": "bldBWuL2Nwmh",
        "colab_type": "code",
        "outputId": "1c6b54c6-35ec-4fa8-b1a5-dd9bcd42b013",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "cell_type": "code",
      "source": [
        "!head book30-listing-train-with-headers.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ",ASIN,FILENAME,IMAGE URL,TITLE,AUTHOR,CATEGORYID,CATEGORY\n",
            "0,1404803335,1404803335.jpg,http://ecx.images-amazon.com/images/I/51UJnL3Tx6L.jpg,\"Magnets: Pulling Together, Pushing Apart (Amazing Science)\",Natalie M. Rosinsky,4,Children's Books\n",
            "1,1446276082,1446276082.jpg,http://ecx.images-amazon.com/images/I/51MGUKhkyhL.jpg,Energy Security (SAGE Library of International Security),,10,Engineering & Transportation\n",
            "2,1491522666,1491522666.jpg,http://ecx.images-amazon.com/images/I/51qKvjsi3ML.jpg,An Amish Gathering: Life in Lancaster County,Beth Wiseman,9,Christian Books & Bibles\n",
            "3,970096410,0970096410.jpg,http://ecx.images-amazon.com/images/I/51qoUENb1CL.jpg,City of Rocks Idaho: A Climber's Guide (Regional Rock Climbing Series),Dave Bingham,26,Sports & Outdoors\n",
            "4,8436808053,8436808053.jpg,http://ecx.images-amazon.com/images/I/41aDW5pzZBL.jpg,\"Como vencer el insomnio. Tecnicas, reglas y consejos practicos para dormir mejor (BIBLIOTECA PRACTICA) (Spanish Edition)\",Choliz Montanes,11,\"Health, Fitness & Dieting\"\n",
            "5,1848291388,1848291388.jpg,http://ecx.images-amazon.com/images/I/51Lpg7xmrBL.jpg,John Martin Littlejohn: An Enigma of Osteopathy,John O'Brien,16,Medical Books\n",
            "6,73402656,0073402656.jpg,http://ecx.images-amazon.com/images/I/51WccSzFUrL.jpg,Chemistry: The Molecular Nature of Matter and Change,Martin Silberberg,23,Science & Math\n",
            "7,323045979,0323045979.jpg,http://ecx.images-amazon.com/images/I/51rJir5EpnL.jpg,\"Mosby's Oncology Nursing Advisor: A Comprehensive Guide to Clinical Practice, 1e\",Susan Newton MS  RN  AOCN  AOCNS,16,Medical Books\n",
            "8,1847176968,1847176968.jpg,http://ecx.images-amazon.com/images/I/61KoC743OzL.jpg,Ireland's Wild Atlantic Way,Carsten Krieger,29,Travel\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ous6EqC8Nocg",
        "colab_type": "code",
        "outputId": "398add9c-ef76-47e2-9fbb-219c8ff1af53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "cell_type": "code",
      "source": [
        "!cat model_definition.yaml"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_features:\n",
            "    -\n",
            "        name: TITLE\n",
            "        type: text\n",
            "        encoder: parallel_cnn\n",
            "        level: word\n",
            "\n",
            "output_features:\n",
            "    -\n",
            "        name: CATEGORY\n",
            "        type: category"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WpVA2fyXLRoK",
        "colab_type": "code",
        "outputId": "abfc3b5b-6f59-469f-cb7b-aff5e28cb8ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 20338
        }
      },
      "cell_type": "code",
      "source": [
        "!ludwig experiment --data_csv book30-listing-train-with-headers.csv --model_definition_file model_definition.yaml\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " _         _        _      \n",
            "| |_  _ __| |_ __ _(_)__ _ \n",
            "| | || / _` \\ V  V / / _` |\n",
            "|_|\\_,_\\__,_|\\_/\\_/|_\\__, |\n",
            "                     |___/ \n",
            "ludwig v0.1.0 - Experiment\n",
            "\n",
            "Experiment name: experiment\n",
            "Model name: run\n",
            "Output path: results/experiment_run_0\n",
            "\n",
            "ludwig_version: '0.1.0'\n",
            "command: ('/usr/local/bin/ludwig experiment --data_csv '\n",
            " 'book30-listing-train-with-headers.csv --model_definition_file '\n",
            " 'model_definition.yaml')\n",
            "dataset_type: 'book30-listing-train-with-headers.csv'\n",
            "model_definition: {   'combiner': {'type': 'concat'},\n",
            "    'input_features': [   {   'encoder': 'parallel_cnn',\n",
            "                              'level': 'word',\n",
            "                              'name': 'TITLE',\n",
            "                              'tied_weights': None,\n",
            "                              'type': 'text'}],\n",
            "    'output_features': [   {   'dependencies': [],\n",
            "                               'loss': {   'class_distance_temperature': 0,\n",
            "                                           'class_weights': 1,\n",
            "                                           'confidence_penalty': 0,\n",
            "                                           'distortion': 1,\n",
            "                                           'labels_smoothing': 0,\n",
            "                                           'negative_samples': 0,\n",
            "                                           'robust_lambda': 0,\n",
            "                                           'sampler': None,\n",
            "                                           'type': 'softmax_cross_entropy',\n",
            "                                           'unique': False,\n",
            "                                           'weight': 1},\n",
            "                               'name': 'CATEGORY',\n",
            "                               'reduce_dependencies': 'sum',\n",
            "                               'reduce_input': 'sum',\n",
            "                               'top_k': 3,\n",
            "                               'type': 'category'}],\n",
            "    'preprocessing': {   'bag': {   'fill_value': '',\n",
            "                                    'format': 'space',\n",
            "                                    'lowercase': 10000,\n",
            "                                    'missing_value_strategy': 'fill_with_const',\n",
            "                                    'most_common': False},\n",
            "                         'binary': {   'fill_value': 0,\n",
            "                                       'missing_value_strategy': 'fill_with_const'},\n",
            "                         'category': {   'fill_value': '<UNK>',\n",
            "                                         'lowercase': False,\n",
            "                                         'missing_value_strategy': 'fill_with_const',\n",
            "                                         'most_common': 10000},\n",
            "                         'force_split': False,\n",
            "                         'image': {'missing_value_strategy': 'backfill'},\n",
            "                         'numerical': {   'fill_value': 0,\n",
            "                                          'missing_value_strategy': 'fill_with_const'},\n",
            "                         'sequence': {   'fill_value': '',\n",
            "                                         'format': 'space',\n",
            "                                         'lowercase': False,\n",
            "                                         'missing_value_strategy': 'fill_with_const',\n",
            "                                         'most_common': 20000,\n",
            "                                         'padding': 'right',\n",
            "                                         'padding_symbol': '<PAD>',\n",
            "                                         'sequence_length_limit': 256,\n",
            "                                         'unknown_symbol': '<UNK>'},\n",
            "                         'set': {   'fill_value': '',\n",
            "                                    'format': 'space',\n",
            "                                    'lowercase': False,\n",
            "                                    'missing_value_strategy': 'fill_with_const',\n",
            "                                    'most_common': 10000},\n",
            "                         'split_probabilities': (0.7, 0.1, 0.2),\n",
            "                         'stratify': None,\n",
            "                         'text': {   'char_format': 'characters',\n",
            "                                     'char_most_common': 70,\n",
            "                                     'char_sequence_length_limit': 1024,\n",
            "                                     'fill_value': '',\n",
            "                                     'lowercase': True,\n",
            "                                     'missing_value_strategy': 'fill_with_const',\n",
            "                                     'padding': 'right',\n",
            "                                     'padding_symbol': '<PAD>',\n",
            "                                     'unknown_symbol': '<UNK>',\n",
            "                                     'word_format': 'space_punct',\n",
            "                                     'word_most_common': 20000,\n",
            "                                     'word_sequence_length_limit': 256},\n",
            "                         'timeseries': {   'fill_value': '',\n",
            "                                           'format': 'space',\n",
            "                                           'missing_value_strategy': 'fill_with_const',\n",
            "                                           'padding': 'right',\n",
            "                                           'padding_value': 0,\n",
            "                                           'timeseries_length_limit': 256}},\n",
            "    'training': {   'batch_size': 128,\n",
            "                    'bucketing_field': None,\n",
            "                    'decay': False,\n",
            "                    'decay_rate': 0.96,\n",
            "                    'decay_steps': 10000,\n",
            "                    'dropout_rate': 0.0,\n",
            "                    'early_stop': 3,\n",
            "                    'epochs': 200,\n",
            "                    'gradient_clipping': None,\n",
            "                    'increase_batch_size_on_plateau': 0,\n",
            "                    'increase_batch_size_on_plateau_max': 512,\n",
            "                    'increase_batch_size_on_plateau_patience': 5,\n",
            "                    'increase_batch_size_on_plateau_rate': 2,\n",
            "                    'learning_rate': 0.001,\n",
            "                    'learning_rate_warmup_epochs': 5,\n",
            "                    'optimizer': {   'beta1': 0.9,\n",
            "                                     'beta2': 0.999,\n",
            "                                     'epsilon': 1e-08,\n",
            "                                     'type': 'adam'},\n",
            "                    'reduce_learning_rate_on_plateau': 0,\n",
            "                    'reduce_learning_rate_on_plateau_patience': 5,\n",
            "                    'reduce_learning_rate_on_plateau_rate': 0.5,\n",
            "                    'regularization_lambda': 0,\n",
            "                    'regularizer': 'l2',\n",
            "                    'staircase': False,\n",
            "                    'validation_field': 'combined',\n",
            "                    'validation_measure': 'loss'}}\n",
            "\n",
            "Using full raw csv, no hdf5 and json file with the same name have been found\n",
            "Building dataset (it may take a while)\n",
            "Loading NLP pipeline\n",
            "Writing dataset\n",
            "Writing train set metadata with vocabulary\n",
            "Training set: 36059\n",
            "Validation set: 5042\n",
            "Test set: 10198\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "\n",
            "╒══════════╕\n",
            "│ TRAINING │\n",
            "╘══════════╛\n",
            "\n",
            "2019-02-18 01:21:33.899464: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2019-02-18 01:21:33.899801: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x318ac00 executing computations on platform Host. Devices:\n",
            "2019-02-18 01:21:33.899835: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-02-18 01:21:34.055715: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-02-18 01:21:34.056285: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x318a100 executing computations on platform CUDA. Devices:\n",
            "2019-02-18 01:21:34.056320: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-02-18 01:21:34.056733: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
            "2019-02-18 01:21:34.056767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
            "2019-02-18 01:21:43.842054: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-02-18 01:21:43.842116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
            "2019-02-18 01:21:43.842133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
            "2019-02-18 01:21:43.842364: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-02-18 01:21:43.842446: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10752 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "\n",
            "Epoch   1\n",
            "Training:   0% 0/282 [00:00<?, ?it/s]2019-02-18 01:21:44.623868: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\n",
            "Training: 100% 282/282 [00:20<00:00, 13.95it/s]\n",
            "Evaluation train: 100% 282/282 [00:04<00:00, 59.52it/s]\n",
            "Evaluation vali : 100% 40/40 [00:00<00:00, 59.33it/s]\n",
            "Evaluation test : 100% 80/80 [00:01<00:00, 52.80it/s]\n",
            "Took 27.3456s\n",
            "╒════════════╤════════╤════════════╤═════════════╕\n",
            "│ CATEGORY   │   loss │   accuracy │   hits_at_k │\n",
            "╞════════════╪════════╪════════════╪═════════════╡\n",
            "│ train      │ 3.3077 │     0.0791 │      0.1855 │\n",
            "├────────────┼────────┼────────────┼─────────────┤\n",
            "│ vali       │ 3.3093 │     0.0768 │      0.1813 │\n",
            "├────────────┼────────┼────────────┼─────────────┤\n",
            "│ test       │ 3.3204 │     0.0757 │      0.1757 │\n",
            "╘════════════╧════════╧════════════╧═════════════╛\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch   2\n",
            "Training: 100% 282/282 [00:17<00:00, 16.85it/s]\n",
            "Evaluation train: 100% 282/282 [00:04<00:00, 59.75it/s]\n",
            "Evaluation vali : 100% 40/40 [00:00<00:00, 60.45it/s]\n",
            "Evaluation test : 100% 80/80 [00:01<00:00, 59.97it/s]\n",
            "Took 23.9509s\n",
            "╒════════════╤════════╤════════════╤═════════════╕\n",
            "│ CATEGORY   │   loss │   accuracy │   hits_at_k │\n",
            "╞════════════╪════════╪════════════╪═════════════╡\n",
            "│ train      │ 3.2823 │     0.0904 │      0.2009 │\n",
            "├────────────┼────────┼────────────┼─────────────┤\n",
            "│ vali       │ 3.2871 │     0.0851 │      0.1962 │\n",
            "├────────────┼────────┼────────────┼─────────────┤\n",
            "│ test       │ 3.3021 │     0.0828 │      0.1897 │\n",
            "╘════════════╧════════╧════════════╧═════════════╛\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch   3\n",
            "Training: 100% 282/282 [00:17<00:00, 16.92it/s]\n",
            "Evaluation train: 100% 282/282 [00:04<00:00, 59.96it/s]\n",
            "Evaluation vali : 100% 40/40 [00:00<00:00, 59.63it/s]\n",
            "Evaluation test : 100% 80/80 [00:01<00:00, 60.28it/s]\n",
            "Took 23.9664s\n",
            "╒════════════╤════════╤════════════╤═════════════╕\n",
            "│ CATEGORY   │   loss │   accuracy │   hits_at_k │\n",
            "╞════════════╪════════╪════════════╪═════════════╡\n",
            "│ train      │ 3.2728 │     0.0940 │      0.2102 │\n",
            "├────────────┼────────┼────────────┼─────────────┤\n",
            "│ vali       │ 3.2773 │     0.0898 │      0.2071 │\n",
            "├────────────┼────────┼────────────┼─────────────┤\n",
            "│ test       │ 3.2966 │     0.0838 │      0.1968 │\n",
            "╘════════════╧════════╧════════════╧═════════════╛\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch   4\n",
            "Training: 100% 282/282 [00:17<00:00, 16.86it/s]\n",
            "Evaluation train: 100% 282/282 [00:04<00:00, 59.63it/s]\n",
            "Evaluation vali : 100% 40/40 [00:00<00:00, 61.04it/s]\n",
            "Evaluation test : 100% 80/80 [00:01<00:00, 59.69it/s]\n",
            "Took 23.9503s\n",
            "╒════════════╤════════╤════════════╤═════════════╕\n",
            "│ CATEGORY   │   loss │   accuracy │   hits_at_k │\n",
            "╞════════════╪════════╪════════════╪═════════════╡\n",
            "│ train      │ 3.2530 │     0.0970 │      0.2159 │\n",
            "├────────────┼────────┼────────────┼─────────────┤\n",
            "│ vali       │ 3.2623 │     0.0926 │      0.2081 │\n",
            "├────────────┼────────┼────────────┼─────────────┤\n",
            "│ test       │ 3.2824 │     0.0884 │      0.2033 │\n",
            "╘════════════╧════════╧════════════╧═════════════╛\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch   5\n",
            "Training: 100% 282/282 [00:17<00:00, 16.83it/s]\n",
            "Evaluation train: 100% 282/282 [00:04<00:00, 60.61it/s]\n",
            "Evaluation vali : 100% 40/40 [00:00<00:00, 59.69it/s]\n",
            "Evaluation test : 100% 80/80 [00:01<00:00, 60.04it/s]\n",
            "Took 23.9652s\n",
            "╒════════════╤════════╤════════════╤═════════════╕\n",
            "│ CATEGORY   │   loss │   accuracy │   hits_at_k │\n",
            "╞════════════╪════════╪════════════╪═════════════╡\n",
            "│ train      │ 3.2445 │     0.0983 │      0.2182 │\n",
            "├────────────┼────────┼────────────┼─────────────┤\n",
            "│ vali       │ 3.2562 │     0.0908 │      0.2130 │\n",
            "├────────────┼────────┼────────────┼─────────────┤\n",
            "│ test       │ 3.2762 │     0.0875 │      0.2024 │\n",
            "╘════════════╧════════╧════════════╧═════════════╛\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch   6\n",
            "Training: 100% 282/282 [00:17<00:00, 16.85it/s]\n",
            "Evaluation train: 100% 282/282 [00:04<00:00, 59.89it/s]\n",
            "Evaluation vali : 100% 40/40 [00:00<00:00, 60.76it/s]\n",
            "Evaluation test : 100% 80/80 [00:01<00:00, 60.00it/s]\n",
            "Took 23.9497s\n",
            "╒════════════╤════════╤════════════╤═════════════╕\n",
            "│ CATEGORY   │   loss │   accuracy │   hits_at_k │\n",
            "╞════════════╪════════╪════════════╪═════════════╡\n",
            "│ train      │ 3.2367 │     0.1004 │      0.2211 │\n",
            "├────────────┼────────┼────────────┼─────────────┤\n",
            "│ vali       │ 3.2543 │     0.0898 │      0.2098 │\n",
            "├────────────┼────────┼────────────┼─────────────┤\n",
            "│ test       │ 3.2740 │     0.0868 │      0.2043 │\n",
            "╘════════════╧════════╧════════════╧═════════════╛\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch   7\n",
            "Training: 100% 282/282 [00:17<00:00, 16.83it/s]\n",
            "Evaluation train: 100% 282/282 [00:04<00:00, 60.08it/s]\n",
            "Evaluation vali : 100% 40/40 [00:00<00:00, 61.33it/s]\n",
            "Evaluation test : 100% 80/80 [00:01<00:00, 60.27it/s]\n",
            "Took 23.9176s\n",
            "╒════════════╤════════╤════════════╤═════════════╕\n",
            "│ CATEGORY   │   loss │   accuracy │   hits_at_k │\n",
            "╞════════════╪════════╪════════════╪═════════════╡\n",
            "│ train      │ 3.2357 │     0.1012 │      0.2220 │\n",
            "├────────────┼────────┼────────────┼─────────────┤\n",
            "│ vali       │ 3.2567 │     0.0916 │      0.2108 │\n",
            "├────────────┼────────┼────────────┼─────────────┤\n",
            "│ test       │ 3.2771 │     0.0880 │      0.2010 │\n",
            "╘════════════╧════════╧════════════╧═════════════╛\n",
            "Last improvement of loss on combined happened 1 epoch ago\n",
            "\n",
            "\n",
            "Epoch   8\n",
            "Training: 100% 282/282 [00:17<00:00, 16.75it/s]\n",
            "Evaluation train: 100% 282/282 [00:04<00:00, 59.96it/s]\n",
            "Evaluation vali : 100% 40/40 [00:00<00:00, 60.53it/s]\n",
            "Evaluation test : 100% 80/80 [00:01<00:00, 60.30it/s]\n",
            "Took 23.9056s\n",
            "╒════════════╤════════╤════════════╤═════════════╕\n",
            "│ CATEGORY   │   loss │   accuracy │   hits_at_k │\n",
            "╞════════════╪════════╪════════════╪═════════════╡\n",
            "│ train      │ 3.2256 │     0.1046 │      0.2259 │\n",
            "├────────────┼────────┼────────────┼─────────────┤\n",
            "│ vali       │ 3.2541 │     0.0934 │      0.2114 │\n",
            "├────────────┼────────┼────────────┼─────────────┤\n",
            "│ test       │ 3.2751 │     0.0913 │      0.1995 │\n",
            "╘════════════╧════════╧════════════╧═════════════╛\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch   9\n",
            "Training: 100% 282/282 [00:17<00:00, 16.76it/s]\n",
            "Evaluation train: 100% 282/282 [00:04<00:00, 60.44it/s]\n",
            "Evaluation vali : 100% 40/40 [00:00<00:00, 61.39it/s]\n",
            "Evaluation test : 100% 80/80 [00:01<00:00, 60.05it/s]\n",
            "Took 23.9047s\n",
            "╒════════════╤════════╤════════════╤═════════════╕\n",
            "│ CATEGORY   │   loss │   accuracy │   hits_at_k │\n",
            "╞════════════╪════════╪════════════╪═════════════╡\n",
            "│ train      │ 3.2222 │     0.1041 │      0.2277 │\n",
            "├────────────┼────────┼────────────┼─────────────┤\n",
            "│ vali       │ 3.2547 │     0.0962 │      0.2164 │\n",
            "├────────────┼────────┼────────────┼─────────────┤\n",
            "│ test       │ 3.2755 │     0.0917 │      0.2004 │\n",
            "╘════════════╧════════╧════════════╧═════════════╛\n",
            "Last improvement of loss on combined happened 1 epoch ago\n",
            "\n",
            "\n",
            "Epoch  10\n",
            "Training: 100% 282/282 [00:17<00:00, 16.97it/s]\n",
            "Evaluation train: 100% 282/282 [00:04<00:00, 59.94it/s]\n",
            "Evaluation vali : 100% 40/40 [00:00<00:00, 61.11it/s]\n",
            "Evaluation test : 100% 80/80 [00:01<00:00, 59.82it/s]\n",
            "Took 23.9255s\n",
            "╒════════════╤════════╤════════════╤═════════════╕\n",
            "│ CATEGORY   │   loss │   accuracy │   hits_at_k │\n",
            "╞════════════╪════════╪════════════╪═════════════╡\n",
            "│ train      │ 3.2181 │     0.1053 │      0.2331 │\n",
            "├────────────┼────────┼────────────┼─────────────┤\n",
            "│ vali       │ 3.2575 │     0.0958 │      0.2196 │\n",
            "├────────────┼────────┼────────────┼─────────────┤\n",
            "│ test       │ 3.2789 │     0.0886 │      0.2082 │\n",
            "╘════════════╧════════╧════════════╧═════════════╛\n",
            "Last improvement of loss on combined happened 2 epochs ago\n",
            "\n",
            "\n",
            "Epoch  11\n",
            "Training: 100% 282/282 [00:17<00:00, 16.88it/s]\n",
            "Evaluation train: 100% 282/282 [00:04<00:00, 59.83it/s]\n",
            "Evaluation vali : 100% 40/40 [00:00<00:00, 60.48it/s]\n",
            "Evaluation test : 100% 80/80 [00:01<00:00, 60.10it/s]\n",
            "Took 23.8798s\n",
            "╒════════════╤════════╤════════════╤═════════════╕\n",
            "│ CATEGORY   │   loss │   accuracy │   hits_at_k │\n",
            "╞════════════╪════════╪════════════╪═════════════╡\n",
            "│ train      │ 3.2211 │     0.1051 │      0.2338 │\n",
            "├────────────┼────────┼────────────┼─────────────┤\n",
            "│ vali       │ 3.2667 │     0.0936 │      0.2140 │\n",
            "├────────────┼────────┼────────────┼─────────────┤\n",
            "│ test       │ 3.2868 │     0.0891 │      0.2045 │\n",
            "╘════════════╧════════╧════════════╧═════════════╛\n",
            "Last improvement of loss on combined happened 3 epochs ago\n",
            "\n",
            "EARLY STOPPING due to lack of validation improvement, it has been 3 epochs since last validation accuracy improvement\n",
            "\n",
            "Best validation model epoch: 8\n",
            "Best validation model loss on validation set combined: 3.2541212318720016\n",
            "Best validation model loss on test set combined: 3.275094079606602\n",
            "\n",
            "╒═════════╕\n",
            "│ PREDICT │\n",
            "╘═════════╛\n",
            "\n",
            "Evaluation: 100% 80/80 [00:01<00:00, 57.96it/s]\n",
            "\n",
            "===== CATEGORY =====\n",
            "accuracy: 0.0891351245342224\n",
            "hits_at_k: 0.20445185330456953\n",
            "loss: 3.286845474856628\n",
            "overall_stats: { 'avg_f1_score_macro': 0.06812071846149517,\n",
            "  'avg_f1_score_micro': 0.0891351245342224,\n",
            "  'avg_f1_score_weighted': 0.06790552679270521,\n",
            "  'avg_precision_macro': 0.09177260758729153,\n",
            "  'avg_precision_micro': 0.0891351245342224,\n",
            "  'avg_precision_weighted': 0.0891351245342224,\n",
            "  'avg_recall_macro': 0.09056387599530688,\n",
            "  'avg_recall_micro': 0.0891351245342224,\n",
            "  'avg_recall_weighted': 0.0891351245342224,\n",
            "  'kappa_score': 0.058034041734078334,\n",
            "  'overall_accuracy': 0.0891351245342224}\n",
            "per_class_stats: {<UNK>: {   'accuracy': 1.0,\n",
            "    'f1_score': 0,\n",
            "    'fall_out': 0.0,\n",
            "    'false_discovery_rate': 1.0,\n",
            "    'false_negative_rate': 1.0,\n",
            "    'false_negatives': 0,\n",
            "    'false_omission_rate': 0.0,\n",
            "    'false_positive_rate': 0.0,\n",
            "    'false_positives': 0,\n",
            "    'hit_rate': 0,\n",
            "    'informedness': 0.0,\n",
            "    'markedness': 0.0,\n",
            "    'matthews_correlation_coefficient': 0,\n",
            "    'miss_rate': 1.0,\n",
            "    'negative_predictive_value': 1.0,\n",
            "    'positive_predictive_value': 0,\n",
            "    'precision': 0,\n",
            "    'recall': 0,\n",
            "    'sensitivity': 0,\n",
            "    'specificity': 1.0,\n",
            "    'true_negative_rate': 1.0,\n",
            "    'true_negatives': 10198,\n",
            "    'true_positive_rate': 0,\n",
            "    'true_positives': 0},\n",
            "  Children's Books: {   'accuracy': 0.9269464600902138,\n",
            "    'f1_score': 0.10991636798088411,\n",
            "    'fall_out': 0.02880446004542636,\n",
            "    'false_discovery_rate': 0.8584615384615385,\n",
            "    'false_negative_rate': 0.91015625,\n",
            "    'false_negatives': 466,\n",
            "    'false_omission_rate': 0.04719943279651573,\n",
            "    'false_positive_rate': 0.02880446004542636,\n",
            "    'false_positives': 279,\n",
            "    'hit_rate': 0.08984375,\n",
            "    'informedness': 0.06103928995457375,\n",
            "    'markedness': 0.09433902874194589,\n",
            "    'matthews_correlation_coefficient': 0.07588403869993006,\n",
            "    'miss_rate': 0.91015625,\n",
            "    'negative_predictive_value': 0.9528005672034843,\n",
            "    'positive_predictive_value': 0.14153846153846153,\n",
            "    'precision': 0.14153846153846153,\n",
            "    'recall': 0.08984375,\n",
            "    'sensitivity': 0.08984375,\n",
            "    'specificity': 0.9711955399545736,\n",
            "    'true_negative_rate': 0.9711955399545736,\n",
            "    'true_negatives': 9407,\n",
            "    'true_positive_rate': 0.08984375,\n",
            "    'true_positives': 46},\n",
            "  Engineering & Transportation: {   'accuracy': 0.963326142380859,\n",
            "    'f1_score': 0.04591836734693878,\n",
            "    'fall_out': 0.029946629768728972,\n",
            "    'false_discovery_rate': 0.9711538461538461,\n",
            "    'false_negative_rate': 0.8875,\n",
            "    'false_negatives': 71,\n",
            "    'false_omission_rate': 0.0071818733562614145,\n",
            "    'false_positive_rate': 0.029946629768728972,\n",
            "    'false_positives': 303,\n",
            "    'hit_rate': 0.1125,\n",
            "    'informedness': 0.08255337023127107,\n",
            "    'markedness': 0.02166428048989233,\n",
            "    'matthews_correlation_coefficient': 0.042290180516003875,\n",
            "    'miss_rate': 0.8875,\n",
            "    'negative_predictive_value': 0.9928181266437386,\n",
            "    'positive_predictive_value': 0.028846153846153848,\n",
            "    'precision': 0.028846153846153848,\n",
            "    'recall': 0.1125,\n",
            "    'sensitivity': 0.1125,\n",
            "    'specificity': 0.970053370231271,\n",
            "    'true_negative_rate': 0.970053370231271,\n",
            "    'true_negatives': 9815,\n",
            "    'true_positive_rate': 0.1125,\n",
            "    'true_positives': 9},\n",
            "  Christian Books & Bibles: {   'accuracy': 0.9656795450088252,\n",
            "    'f1_score': 0.005681818181818181,\n",
            "    'fall_out': 0.034229109454688156,\n",
            "    'false_discovery_rate': 0.9971428571428571,\n",
            "    'false_negative_rate': 0.5,\n",
            "    'false_negatives': 1,\n",
            "    'false_omission_rate': 0.00010154346060109454,\n",
            "    'false_positive_rate': 0.034229109454688156,\n",
            "    'false_positives': 349,\n",
            "    'hit_rate': 0.5,\n",
            "    'informedness': 0.46577089054531173,\n",
            "    'markedness': 0.002755599396541797,\n",
            "    'matthews_correlation_coefficient': 0.035825660983621235,\n",
            "    'miss_rate': 0.5,\n",
            "    'negative_predictive_value': 0.9998984565393989,\n",
            "    'positive_predictive_value': 0.002857142857142857,\n",
            "    'precision': 0.002857142857142857,\n",
            "    'recall': 0.5,\n",
            "    'sensitivity': 0.5,\n",
            "    'specificity': 0.9657708905453118,\n",
            "    'true_negative_rate': 0.9657708905453118,\n",
            "    'true_negatives': 9847,\n",
            "    'true_positive_rate': 0.5,\n",
            "    'true_positives': 1},\n",
            "  Sports & Outdoors: {   'accuracy': 0.963424200823691,\n",
            "    'f1_score': 0,\n",
            "    'fall_out': 0.03297244094488194,\n",
            "    'false_discovery_rate': 1.0,\n",
            "    'false_negative_rate': 1.0,\n",
            "    'false_negatives': 38,\n",
            "    'false_omission_rate': 0.0038527831288655,\n",
            "    'false_positive_rate': 0.03297244094488194,\n",
            "    'false_positives': 335,\n",
            "    'hit_rate': 0.0,\n",
            "    'informedness': -0.03297244094488194,\n",
            "    'markedness': -0.0038527831288655,\n",
            "    'matthews_correlation_coefficient': -0.011271009901067143,\n",
            "    'miss_rate': 1.0,\n",
            "    'negative_predictive_value': 0.9961472168711345,\n",
            "    'positive_predictive_value': 0.0,\n",
            "    'precision': 0.0,\n",
            "    'recall': 0.0,\n",
            "    'sensitivity': 0.0,\n",
            "    'specificity': 0.9670275590551181,\n",
            "    'true_negative_rate': 0.9670275590551181,\n",
            "    'true_negatives': 9825,\n",
            "    'true_positive_rate': 0.0,\n",
            "    'true_positives': 0},\n",
            "  Health, Fitness & Dieting: {   'accuracy': 0.9297901549323396,\n",
            "    'f1_score': 0.0427807486631016,\n",
            "    'fall_out': 0.03329248366013071,\n",
            "    'false_discovery_rate': 0.9532163742690059,\n",
            "    'false_negative_rate': 0.9605911330049262,\n",
            "    'false_negatives': 390,\n",
            "    'false_omission_rate': 0.03956980519480524,\n",
            "    'false_positive_rate': 0.03329248366013071,\n",
            "    'false_positives': 326,\n",
            "    'hit_rate': 0.03940886699507389,\n",
            "    'informedness': 0.006116383334943132,\n",
            "    'markedness': 0.0072138205361889085,\n",
            "    'matthews_correlation_coefficient': 0.0066424763235420695,\n",
            "    'miss_rate': 0.9605911330049262,\n",
            "    'negative_predictive_value': 0.9604301948051948,\n",
            "    'positive_predictive_value': 0.04678362573099415,\n",
            "    'precision': 0.04678362573099415,\n",
            "    'recall': 0.03940886699507389,\n",
            "    'sensitivity': 0.03940886699507389,\n",
            "    'specificity': 0.9667075163398693,\n",
            "    'true_negative_rate': 0.9667075163398693,\n",
            "    'true_negatives': 9466,\n",
            "    'true_positive_rate': 0.03940886699507389,\n",
            "    'true_positives': 16},\n",
            "  Medical Books: {   'accuracy': 0.9540105903118259,\n",
            "    'f1_score': 0.07495069033530573,\n",
            "    'fall_out': 0.0315180530620387,\n",
            "    'false_discovery_rate': 0.9432835820895522,\n",
            "    'false_negative_rate': 0.8895348837209303,\n",
            "    'false_negatives': 153,\n",
            "    'false_omission_rate': 0.0155125215451688,\n",
            "    'false_positive_rate': 0.0315180530620387,\n",
            "    'false_positives': 316,\n",
            "    'hit_rate': 0.11046511627906977,\n",
            "    'informedness': 0.07894706321703104,\n",
            "    'markedness': 0.04120389636527899,\n",
            "    'matthews_correlation_coefficient': 0.05703443355673547,\n",
            "    'miss_rate': 0.8895348837209303,\n",
            "    'negative_predictive_value': 0.9844874784548312,\n",
            "    'positive_predictive_value': 0.056716417910447764,\n",
            "    'precision': 0.056716417910447764,\n",
            "    'recall': 0.11046511627906977,\n",
            "    'sensitivity': 0.11046511627906977,\n",
            "    'specificity': 0.9684819469379613,\n",
            "    'true_negative_rate': 0.9684819469379613,\n",
            "    'true_negatives': 9710,\n",
            "    'true_positive_rate': 0.11046511627906977,\n",
            "    'true_positives': 19},\n",
            "  Science & Math: {   'accuracy': 0.9558737007256325,\n",
            "    'f1_score': 0.030172413793103446,\n",
            "    'fall_out': 0.036212525972098564,\n",
            "    'false_discovery_rate': 0.9812332439678284,\n",
            "    'false_negative_rate': 0.9230769230769231,\n",
            "    'false_negatives': 84,\n",
            "    'false_omission_rate': 0.008549618320610741,\n",
            "    'false_positive_rate': 0.036212525972098564,\n",
            "    'false_positives': 366,\n",
            "    'hit_rate': 0.07692307692307693,\n",
            "    'informedness': 0.04071055095097842,\n",
            "    'markedness': 0.010217137711560742,\n",
            "    'matthews_correlation_coefficient': 0.020394737198102416,\n",
            "    'miss_rate': 0.9230769230769231,\n",
            "    'negative_predictive_value': 0.9914503816793893,\n",
            "    'positive_predictive_value': 0.01876675603217158,\n",
            "    'precision': 0.01876675603217158,\n",
            "    'recall': 0.07692307692307693,\n",
            "    'sensitivity': 0.07692307692307693,\n",
            "    'specificity': 0.9637874740279014,\n",
            "    'true_negative_rate': 0.9637874740279014,\n",
            "    'true_negatives': 9741,\n",
            "    'true_positive_rate': 0.07692307692307693,\n",
            "    'true_positives': 7},\n",
            "  Travel: {   'accuracy': 0.9540105903118259,\n",
            "    'f1_score': 0.016771488469601678,\n",
            "    'fall_out': 0.030505433157212658,\n",
            "    'false_discovery_rate': 0.9870967741935484,\n",
            "    'false_negative_rate': 0.9760479041916168,\n",
            "    'false_negatives': 163,\n",
            "    'false_omission_rate': 0.016484627831715226,\n",
            "    'false_positive_rate': 0.030505433157212658,\n",
            "    'false_positives': 306,\n",
            "    'hit_rate': 0.023952095808383235,\n",
            "    'informedness': -0.006553337348829458,\n",
            "    'markedness': -0.0035814020252635803,\n",
            "    'matthews_correlation_coefficient': -0.004844598606007852,\n",
            "    'miss_rate': 0.9760479041916168,\n",
            "    'negative_predictive_value': 0.9835153721682848,\n",
            "    'positive_predictive_value': 0.012903225806451613,\n",
            "    'precision': 0.012903225806451613,\n",
            "    'recall': 0.023952095808383235,\n",
            "    'sensitivity': 0.023952095808383235,\n",
            "    'specificity': 0.9694945668427873,\n",
            "    'true_negative_rate': 0.9694945668427873,\n",
            "    'true_negatives': 9725,\n",
            "    'true_positive_rate': 0.023952095808383235,\n",
            "    'true_positives': 4},\n",
            "  Business & Money: {   'accuracy': 0.9681310060796234,\n",
            "    'f1_score': 0,\n",
            "    'fall_out': 0.030823598704230903,\n",
            "    'false_discovery_rate': 1.0,\n",
            "    'false_negative_rate': 1.0,\n",
            "    'false_negatives': 11,\n",
            "    'false_omission_rate': 0.0011129097531363819,\n",
            "    'false_positive_rate': 0.030823598704230903,\n",
            "    'false_positives': 314,\n",
            "    'hit_rate': 0.0,\n",
            "    'informedness': -0.030823598704230903,\n",
            "    'markedness': -0.0011129097531363819,\n",
            "    'matthews_correlation_coefficient': -0.00585695173487886,\n",
            "    'miss_rate': 1.0,\n",
            "    'negative_predictive_value': 0.9988870902468636,\n",
            "    'positive_predictive_value': 0.0,\n",
            "    'precision': 0.0,\n",
            "    'recall': 0.0,\n",
            "    'sensitivity': 0.0,\n",
            "    'specificity': 0.9691764012957691,\n",
            "    'true_negative_rate': 0.9691764012957691,\n",
            "    'true_negatives': 9873,\n",
            "    'true_positive_rate': 0.0,\n",
            "    'true_positives': 0},\n",
            "  Cookbooks, Food & Wine: {   'accuracy': 0.9595018631104139,\n",
            "    'f1_score': 0.019002375296912115,\n",
            "    'fall_out': 0.03492846571287622,\n",
            "    'false_discovery_rate': 0.9888268156424581,\n",
            "    'false_negative_rate': 0.9365079365079365,\n",
            "    'false_negatives': 59,\n",
            "    'false_omission_rate': 0.00599593495934958,\n",
            "    'false_positive_rate': 0.03492846571287622,\n",
            "    'false_positives': 354,\n",
            "    'hit_rate': 0.06349206349206349,\n",
            "    'informedness': 0.028563597779187155,\n",
            "    'markedness': 0.005177249398192307,\n",
            "    'matthews_correlation_coefficient': 0.012160627837924515,\n",
            "    'miss_rate': 0.9365079365079365,\n",
            "    'negative_predictive_value': 0.9940040650406504,\n",
            "    'positive_predictive_value': 0.0111731843575419,\n",
            "    'precision': 0.0111731843575419,\n",
            "    'recall': 0.06349206349206349,\n",
            "    'sensitivity': 0.06349206349206349,\n",
            "    'specificity': 0.9650715342871238,\n",
            "    'true_negative_rate': 0.9650715342871238,\n",
            "    'true_negatives': 9781,\n",
            "    'true_positive_rate': 0.06349206349206349,\n",
            "    'true_positives': 4},\n",
            "  Politics & Social Sciences: {   'accuracy': 0.928025102961365,\n",
            "    'f1_score': 0.0516795865633075,\n",
            "    'fall_out': 0.035834609494640124,\n",
            "    'false_discovery_rate': 0.9460916442048517,\n",
            "    'false_negative_rate': 0.9503722084367245,\n",
            "    'false_negatives': 383,\n",
            "    'false_omission_rate': 0.03897425460466064,\n",
            "    'false_positive_rate': 0.035834609494640124,\n",
            "    'false_positives': 351,\n",
            "    'hit_rate': 0.04962779156327544,\n",
            "    'informedness': 0.013793182068635224,\n",
            "    'markedness': 0.014934101190487548,\n",
            "    'matthews_correlation_coefficient': 0.01435230910870509,\n",
            "    'miss_rate': 0.9503722084367245,\n",
            "    'negative_predictive_value': 0.9610257453953394,\n",
            "    'positive_predictive_value': 0.05390835579514825,\n",
            "    'precision': 0.05390835579514825,\n",
            "    'recall': 0.04962779156327544,\n",
            "    'sensitivity': 0.04962779156327544,\n",
            "    'specificity': 0.9641653905053599,\n",
            "    'true_negative_rate': 0.9641653905053599,\n",
            "    'true_negatives': 9444,\n",
            "    'true_positive_rate': 0.04962779156327544,\n",
            "    'true_positives': 20},\n",
            "  Crafts, Hobbies & Home: {   'accuracy': 0.9681310060796234,\n",
            "    'f1_score': 0,\n",
            "    'fall_out': 0.0312990580847724,\n",
            "    'false_discovery_rate': 1.0,\n",
            "    'false_negative_rate': 1.0,\n",
            "    'false_negatives': 6,\n",
            "    'false_omission_rate': 0.000607348921955686,\n",
            "    'false_positive_rate': 0.0312990580847724,\n",
            "    'false_positives': 319,\n",
            "    'hit_rate': 0.0,\n",
            "    'informedness': -0.0312990580847724,\n",
            "    'markedness': -0.000607348921955686,\n",
            "    'matthews_correlation_coefficient': -0.004359982704783838,\n",
            "    'miss_rate': 1.0,\n",
            "    'negative_predictive_value': 0.9993926510780443,\n",
            "    'positive_predictive_value': 0.0,\n",
            "    'precision': 0.0,\n",
            "    'recall': 0.0,\n",
            "    'sensitivity': 0.0,\n",
            "    'specificity': 0.9687009419152276,\n",
            "    'true_negative_rate': 0.9687009419152276,\n",
            "    'true_negatives': 9873,\n",
            "    'true_positive_rate': 0.0,\n",
            "    'true_positives': 0},\n",
            "  Religion & Spirituality: {   'accuracy': 0.957834869582271,\n",
            "    'f1_score': 0.009216589861751152,\n",
            "    'fall_out': 0.03517091483896462,\n",
            "    'false_discovery_rate': 0.994413407821229,\n",
            "    'false_negative_rate': 0.9736842105263158,\n",
            "    'false_negatives': 74,\n",
            "    'false_omission_rate': 0.007520325203252076,\n",
            "    'false_positive_rate': 0.03517091483896462,\n",
            "    'false_positives': 356,\n",
            "    'hit_rate': 0.02631578947368421,\n",
            "    'informedness': -0.008855125365280436,\n",
            "    'markedness': -0.0019337330244810769,\n",
            "    'matthews_correlation_coefficient': -0.004138048858431092,\n",
            "    'miss_rate': 0.9736842105263158,\n",
            "    'negative_predictive_value': 0.9924796747967479,\n",
            "    'positive_predictive_value': 0.00558659217877095,\n",
            "    'precision': 0.00558659217877095,\n",
            "    'recall': 0.02631578947368421,\n",
            "    'sensitivity': 0.02631578947368421,\n",
            "    'specificity': 0.9648290851610354,\n",
            "    'true_negative_rate': 0.9648290851610354,\n",
            "    'true_negatives': 9766,\n",
            "    'true_positive_rate': 0.02631578947368421,\n",
            "    'true_positives': 2},\n",
            "  Literature & Fiction: {   'accuracy': 0.9111590507942734,\n",
            "    'f1_score': 0.12884615384615386,\n",
            "    'fall_out': 0.03088559722659945,\n",
            "    'false_discovery_rate': 0.814404432132964,\n",
            "    'false_negative_rate': 0.9013254786450663,\n",
            "    'false_negatives': 612,\n",
            "    'false_omission_rate': 0.06221408966148212,\n",
            "    'false_positive_rate': 0.03088559722659945,\n",
            "    'false_positives': 294,\n",
            "    'hit_rate': 0.09867452135493372,\n",
            "    'informedness': 0.06778892412833426,\n",
            "    'markedness': 0.12338147820555401,\n",
            "    'matthews_correlation_coefficient': 0.09145434743585469,\n",
            "    'miss_rate': 0.9013254786450663,\n",
            "    'negative_predictive_value': 0.9377859103385179,\n",
            "    'positive_predictive_value': 0.18559556786703602,\n",
            "    'precision': 0.18559556786703602,\n",
            "    'recall': 0.09867452135493372,\n",
            "    'sensitivity': 0.09867452135493372,\n",
            "    'specificity': 0.9691144027734006,\n",
            "    'true_negative_rate': 0.9691144027734006,\n",
            "    'true_negatives': 9225,\n",
            "    'true_positive_rate': 0.09867452135493372,\n",
            "    'true_positives': 67},\n",
            "  Humor & Entertainment: {   'accuracy': 0.9680329476367915,\n",
            "    'f1_score': 0,\n",
            "    'fall_out': 0.031492200529775305,\n",
            "    'false_discovery_rate': 1.0,\n",
            "    'false_negative_rate': 1.0,\n",
            "    'false_negatives': 5,\n",
            "    'false_omission_rate': 0.0005062265870203753,\n",
            "    'false_positive_rate': 0.031492200529775305,\n",
            "    'false_positives': 321,\n",
            "    'hit_rate': 0.0,\n",
            "    'informedness': -0.031492200529775305,\n",
            "    'markedness': -0.0005062265870203753,\n",
            "    'matthews_correlation_coefficient': -0.003992767109655738,\n",
            "    'miss_rate': 1.0,\n",
            "    'negative_predictive_value': 0.9994937734129796,\n",
            "    'positive_predictive_value': 0.0,\n",
            "    'precision': 0.0,\n",
            "    'recall': 0.0,\n",
            "    'sensitivity': 0.0,\n",
            "    'specificity': 0.9685077994702247,\n",
            "    'true_negative_rate': 0.9685077994702247,\n",
            "    'true_negatives': 9872,\n",
            "    'true_positive_rate': 0.0,\n",
            "    'true_positives': 0},\n",
            "  Law: {   'accuracy': 0.9264561678760541,\n",
            "    'f1_score': 0.05778894472361809,\n",
            "    'fall_out': 0.03343246846477288,\n",
            "    'false_discovery_rate': 0.9340974212034384,\n",
            "    'false_negative_rate': 0.9485458612975392,\n",
            "    'false_negatives': 424,\n",
            "    'false_omission_rate': 0.04305005584323285,\n",
            "    'false_positive_rate': 0.03343246846477288,\n",
            "    'false_positives': 326,\n",
            "    'hit_rate': 0.05145413870246085,\n",
            "    'informedness': 0.01802167023768808,\n",
            "    'markedness': 0.022852522953328736,\n",
            "    'matthews_correlation_coefficient': 0.020293857020391354,\n",
            "    'miss_rate': 0.9485458612975392,\n",
            "    'negative_predictive_value': 0.9569499441567672,\n",
            "    'positive_predictive_value': 0.0659025787965616,\n",
            "    'precision': 0.0659025787965616,\n",
            "    'recall': 0.05145413870246085,\n",
            "    'sensitivity': 0.05145413870246085,\n",
            "    'specificity': 0.9665675315352271,\n",
            "    'true_negative_rate': 0.9665675315352271,\n",
            "    'true_negatives': 9425,\n",
            "    'true_positive_rate': 0.05145413870246085,\n",
            "    'true_positives': 23},\n",
            "  Computers & Technology: {   'accuracy': 0.9531280643263385,\n",
            "    'f1_score': 0.047808764940239036,\n",
            "    'fall_out': 0.03508597554915016,\n",
            "    'false_discovery_rate': 0.9671232876712329,\n",
            "    'false_negative_rate': 0.9124087591240876,\n",
            "    'false_negatives': 125,\n",
            "    'false_omission_rate': 0.01271229533204521,\n",
            "    'false_positive_rate': 0.03508597554915016,\n",
            "    'false_positives': 353,\n",
            "    'hit_rate': 0.08759124087591241,\n",
            "    'informedness': 0.05250526532676236,\n",
            "    'markedness': 0.02016441699672189,\n",
            "    'matthews_correlation_coefficient': 0.03253825540148643,\n",
            "    'miss_rate': 0.9124087591240876,\n",
            "    'negative_predictive_value': 0.9872877046679548,\n",
            "    'positive_predictive_value': 0.03287671232876712,\n",
            "    'precision': 0.03287671232876712,\n",
            "    'recall': 0.08759124087591241,\n",
            "    'sensitivity': 0.08759124087591241,\n",
            "    'specificity': 0.9649140244508498,\n",
            "    'true_negative_rate': 0.9649140244508498,\n",
            "    'true_negatives': 9708,\n",
            "    'true_positive_rate': 0.08759124087591241,\n",
            "    'true_positives': 12},\n",
            "  Test Preparation: {   'accuracy': 0.9327319082172975,\n",
            "    'f1_score': 0.15099009900990099,\n",
            "    'fall_out': 0.027274598600247058,\n",
            "    'false_discovery_rate': 0.8128834355828221,\n",
            "    'false_negative_rate': 0.8734439834024896,\n",
            "    'false_negatives': 421,\n",
            "    'false_omission_rate': 0.04264586709886553,\n",
            "    'false_positive_rate': 0.027274598600247058,\n",
            "    'false_positives': 265,\n",
            "    'hit_rate': 0.12655601659751037,\n",
            "    'informedness': 0.09928141799726342,\n",
            "    'markedness': 0.1444706973183123,\n",
            "    'matthews_correlation_coefficient': 0.11976333198778118,\n",
            "    'miss_rate': 0.8734439834024896,\n",
            "    'negative_predictive_value': 0.9573541329011345,\n",
            "    'positive_predictive_value': 0.18711656441717792,\n",
            "    'precision': 0.18711656441717792,\n",
            "    'recall': 0.12655601659751037,\n",
            "    'sensitivity': 0.12655601659751037,\n",
            "    'specificity': 0.9727254013997529,\n",
            "    'true_negative_rate': 0.9727254013997529,\n",
            "    'true_negatives': 9451,\n",
            "    'true_positive_rate': 0.12655601659751037,\n",
            "    'true_positives': 61},\n",
            "  Arts & Photography: {   'accuracy': 0.941557168072171,\n",
            "    'f1_score': 0.04487179487179488,\n",
            "    'fall_out': 0.03171076550191876,\n",
            "    'false_discovery_rate': 0.9573170731707317,\n",
            "    'false_negative_rate': 0.9527027027027027,\n",
            "    'false_negatives': 282,\n",
            "    'false_omission_rate': 0.02857142857142858,\n",
            "    'false_positive_rate': 0.03171076550191876,\n",
            "    'false_positives': 314,\n",
            "    'hit_rate': 0.0472972972972973,\n",
            "    'informedness': 0.0155865317953785,\n",
            "    'markedness': 0.014111498257839639,\n",
            "    'matthews_correlation_coefficient': 0.01483068832779676,\n",
            "    'miss_rate': 0.9527027027027027,\n",
            "    'negative_predictive_value': 0.9714285714285714,\n",
            "    'positive_predictive_value': 0.042682926829268296,\n",
            "    'precision': 0.042682926829268296,\n",
            "    'recall': 0.0472972972972973,\n",
            "    'sensitivity': 0.0472972972972973,\n",
            "    'specificity': 0.9682892344980812,\n",
            "    'true_negative_rate': 0.9682892344980812,\n",
            "    'true_negatives': 9588,\n",
            "    'true_positive_rate': 0.0472972972972973,\n",
            "    'true_positives': 14},\n",
            "  Parenting & Relationships: {   'accuracy': 0.9494018434987253,\n",
            "    'f1_score': 0.0851063829787234,\n",
            "    'fall_out': 0.035068438405435054,\n",
            "    'false_discovery_rate': 0.9359999999999999,\n",
            "    'false_negative_rate': 0.873015873015873,\n",
            "    'false_negatives': 165,\n",
            "    'false_omission_rate': 0.016797312430011146,\n",
            "    'false_positive_rate': 0.035068438405435054,\n",
            "    'false_positives': 351,\n",
            "    'hit_rate': 0.12698412698412698,\n",
            "    'informedness': 0.09191568857869203,\n",
            "    'markedness': 0.04720268756998891,\n",
            "    'matthews_correlation_coefficient': 0.0658685625375291,\n",
            "    'miss_rate': 0.873015873015873,\n",
            "    'negative_predictive_value': 0.9832026875699889,\n",
            "    'positive_predictive_value': 0.064,\n",
            "    'precision': 0.064,\n",
            "    'recall': 0.12698412698412698,\n",
            "    'sensitivity': 0.12698412698412698,\n",
            "    'specificity': 0.964931561594565,\n",
            "    'true_negative_rate': 0.964931561594565,\n",
            "    'true_negatives': 9658,\n",
            "    'true_positive_rate': 0.12698412698412698,\n",
            "    'true_positives': 24},\n",
            "  Romance: {   'accuracy': 0.9173367326926848,\n",
            "    'f1_score': 0.11542497376705142,\n",
            "    'fall_out': 0.030138700594431134,\n",
            "    'false_discovery_rate': 0.8401162790697674,\n",
            "    'false_negative_rate': 0.909688013136289,\n",
            "    'false_negatives': 554,\n",
            "    'false_omission_rate': 0.05622082403085038,\n",
            "    'false_positive_rate': 0.030138700594431134,\n",
            "    'false_positives': 289,\n",
            "    'hit_rate': 0.090311986863711,\n",
            "    'informedness': 0.06017328626927987,\n",
            "    'markedness': 0.10366289689938224,\n",
            "    'matthews_correlation_coefficient': 0.07897934648140213,\n",
            "    'miss_rate': 0.909688013136289,\n",
            "    'negative_predictive_value': 0.9437791759691496,\n",
            "    'positive_predictive_value': 0.15988372093023256,\n",
            "    'precision': 0.15988372093023256,\n",
            "    'recall': 0.090311986863711,\n",
            "    'sensitivity': 0.090311986863711,\n",
            "    'specificity': 0.9698612994055689,\n",
            "    'true_negative_rate': 0.9698612994055689,\n",
            "    'true_negatives': 9300,\n",
            "    'true_positive_rate': 0.090311986863711,\n",
            "    'true_positives': 55},\n",
            "  History: {   'accuracy': 0.9323396744459698,\n",
            "    'f1_score': 0.07999999999999999,\n",
            "    'fall_out': 0.030978427563643773,\n",
            "    'false_discovery_rate': 0.9099099099099099,\n",
            "    'false_negative_rate': 0.9280575539568345,\n",
            "    'false_negatives': 387,\n",
            "    'false_omission_rate': 0.0392295995945261,\n",
            "    'false_positive_rate': 0.030978427563643773,\n",
            "    'false_positives': 303,\n",
            "    'hit_rate': 0.07194244604316546,\n",
            "    'informedness': 0.04096401847952169,\n",
            "    'markedness': 0.05086049049556407,\n",
            "    'matthews_correlation_coefficient': 0.04564482525476266,\n",
            "    'miss_rate': 0.9280575539568345,\n",
            "    'negative_predictive_value': 0.9607704004054739,\n",
            "    'positive_predictive_value': 0.09009009009009009,\n",
            "    'precision': 0.09009009009009009,\n",
            "    'recall': 0.07194244604316546,\n",
            "    'sensitivity': 0.07194244604316546,\n",
            "    'specificity': 0.9690215724363562,\n",
            "    'true_negative_rate': 0.9690215724363562,\n",
            "    'true_negatives': 9478,\n",
            "    'true_positive_rate': 0.07194244604316546,\n",
            "    'true_positives': 30},\n",
            "  Comics & Graphic Novels: {   'accuracy': 0.9580309864679349,\n",
            "    'f1_score': 0.218978102189781,\n",
            "    'fall_out': 0.028708612583775106,\n",
            "    'false_discovery_rate': 0.8270893371757925,\n",
            "    'false_negative_rate': 0.7014925373134329,\n",
            "    'false_negatives': 141,\n",
            "    'false_omission_rate': 0.014313267688559561,\n",
            "    'false_positive_rate': 0.028708612583775106,\n",
            "    'false_positives': 287,\n",
            "    'hit_rate': 0.29850746268656714,\n",
            "    'informedness': 0.2697988501027919,\n",
            "    'markedness': 0.15859739513564786,\n",
            "    'matthews_correlation_coefficient': 0.20685597607247405,\n",
            "    'miss_rate': 0.7014925373134329,\n",
            "    'negative_predictive_value': 0.9856867323114404,\n",
            "    'positive_predictive_value': 0.1729106628242075,\n",
            "    'precision': 0.1729106628242075,\n",
            "    'recall': 0.29850746268656714,\n",
            "    'sensitivity': 0.29850746268656714,\n",
            "    'specificity': 0.9712913874162249,\n",
            "    'true_negative_rate': 0.9712913874162249,\n",
            "    'true_negatives': 9710,\n",
            "    'true_positive_rate': 0.29850746268656714,\n",
            "    'true_positives': 60},\n",
            "  Reference: {   'accuracy': 0.9581290449107668,\n",
            "    'f1_score': 0.027334851936218676,\n",
            "    'fall_out': 0.034220156265453494,\n",
            "    'false_discovery_rate': 0.9829545454545454,\n",
            "    'false_negative_rate': 0.9310344827586207,\n",
            "    'false_negatives': 81,\n",
            "    'false_omission_rate': 0.00822669104204754,\n",
            "    'false_positive_rate': 0.034220156265453494,\n",
            "    'false_positives': 346,\n",
            "    'hit_rate': 0.06896551724137931,\n",
            "    'informedness': 0.03474536097592584,\n",
            "    'markedness': 0.008818763503406934,\n",
            "    'matthews_correlation_coefficient': 0.01750460286002505,\n",
            "    'miss_rate': 0.9310344827586207,\n",
            "    'negative_predictive_value': 0.9917733089579525,\n",
            "    'positive_predictive_value': 0.017045454545454544,\n",
            "    'precision': 0.017045454545454544,\n",
            "    'recall': 0.06896551724137931,\n",
            "    'sensitivity': 0.06896551724137931,\n",
            "    'specificity': 0.9657798437345465,\n",
            "    'true_negative_rate': 0.9657798437345465,\n",
            "    'true_negatives': 9765,\n",
            "    'true_positive_rate': 0.06896551724137931,\n",
            "    'true_positives': 6},\n",
            "  Teen & Young Adult: {   'accuracy': 0.9515591292410277,\n",
            "    'f1_score': 0.04263565891472868,\n",
            "    'fall_out': 0.034176962933439636,\n",
            "    'false_discovery_rate': 0.9689265536723164,\n",
            "    'false_negative_rate': 0.9320987654320988,\n",
            "    'false_negatives': 151,\n",
            "    'false_omission_rate': 0.015339292970337315,\n",
            "    'false_positive_rate': 0.034176962933439636,\n",
            "    'false_positives': 343,\n",
            "    'hit_rate': 0.06790123456790123,\n",
            "    'informedness': 0.03372427163446168,\n",
            "    'markedness': 0.015734153357346292,\n",
            "    'matthews_correlation_coefficient': 0.023035252587315484,\n",
            "    'miss_rate': 0.9320987654320988,\n",
            "    'negative_predictive_value': 0.9846607070296627,\n",
            "    'positive_predictive_value': 0.031073446327683617,\n",
            "    'precision': 0.031073446327683617,\n",
            "    'recall': 0.06790123456790123,\n",
            "    'sensitivity': 0.06790123456790123,\n",
            "    'specificity': 0.9658230370665604,\n",
            "    'true_negative_rate': 0.9658230370665604,\n",
            "    'true_negatives': 9693,\n",
            "    'true_positive_rate': 0.06790123456790123,\n",
            "    'true_positives': 11},\n",
            "  Self-Help: {   'accuracy': 0.8456560109825456,\n",
            "    'f1_score': 0.11173814898419863,\n",
            "    'fall_out': 0.025380130330398987,\n",
            "    'false_discovery_rate': 0.691588785046729,\n",
            "    'false_negative_rate': 0.9317711922811854,\n",
            "    'false_negatives': 1352,\n",
            "    'false_omission_rate': 0.1368836691303027,\n",
            "    'false_positive_rate': 0.025380130330398987,\n",
            "    'false_positives': 222,\n",
            "    'hit_rate': 0.06822880771881461,\n",
            "    'informedness': 0.04284867738841558,\n",
            "    'markedness': 0.17152754582296836,\n",
            "    'matthews_correlation_coefficient': 0.08573055741213308,\n",
            "    'miss_rate': 0.9317711922811854,\n",
            "    'negative_predictive_value': 0.8631163308696973,\n",
            "    'positive_predictive_value': 0.308411214953271,\n",
            "    'precision': 0.308411214953271,\n",
            "    'recall': 0.06822880771881461,\n",
            "    'sensitivity': 0.06822880771881461,\n",
            "    'specificity': 0.974619869669601,\n",
            "    'true_negative_rate': 0.974619869669601,\n",
            "    'true_negatives': 8525,\n",
            "    'true_positive_rate': 0.06822880771881461,\n",
            "    'true_positives': 99},\n",
            "  Calendars: {   'accuracy': 0.8434006667974112,\n",
            "    'f1_score': 0.19627579265223954,\n",
            "    'fall_out': 0.014421385860007074,\n",
            "    'false_discovery_rate': 0.3867924528301887,\n",
            "    'false_negative_rate': 0.8831635710005992,\n",
            "    'false_negatives': 1474,\n",
            "    'false_omission_rate': 0.14919028340080975,\n",
            "    'false_positive_rate': 0.014421385860007074,\n",
            "    'false_positives': 123,\n",
            "    'hit_rate': 0.11683642899940083,\n",
            "    'informedness': 0.10241504313939376,\n",
            "    'markedness': 0.46401726376900143,\n",
            "    'matthews_correlation_coefficient': 0.21799621117424445,\n",
            "    'miss_rate': 0.8831635710005992,\n",
            "    'negative_predictive_value': 0.8508097165991902,\n",
            "    'positive_predictive_value': 0.6132075471698113,\n",
            "    'precision': 0.6132075471698113,\n",
            "    'recall': 0.11683642899940083,\n",
            "    'sensitivity': 0.11683642899940083,\n",
            "    'specificity': 0.9855786141399929,\n",
            "    'true_negative_rate': 0.9855786141399929,\n",
            "    'true_negatives': 8406,\n",
            "    'true_positive_rate': 0.11683642899940083,\n",
            "    'true_positives': 195},\n",
            "  Science Fiction & Fantasy: {   'accuracy': 0.9561678760541282,\n",
            "    'f1_score': 0.11485148514851486,\n",
            "    'fall_out': 0.027994401119776025,\n",
            "    'false_discovery_rate': 0.9061488673139159,\n",
            "    'false_negative_rate': 0.8520408163265306,\n",
            "    'false_negatives': 167,\n",
            "    'false_omission_rate': 0.016887450702801066,\n",
            "    'false_positive_rate': 0.027994401119776025,\n",
            "    'false_positives': 280,\n",
            "    'hit_rate': 0.14795918367346939,\n",
            "    'informedness': 0.11996478255369336,\n",
            "    'markedness': 0.07696368198328307,\n",
            "    'matthews_correlation_coefficient': 0.09608814377255998,\n",
            "    'miss_rate': 0.8520408163265306,\n",
            "    'negative_predictive_value': 0.9831125492971989,\n",
            "    'positive_predictive_value': 0.09385113268608414,\n",
            "    'precision': 0.09385113268608414,\n",
            "    'recall': 0.14795918367346939,\n",
            "    'sensitivity': 0.14795918367346939,\n",
            "    'specificity': 0.972005598880224,\n",
            "    'true_negative_rate': 0.972005598880224,\n",
            "    'true_negatives': 9722,\n",
            "    'true_positive_rate': 0.14795918367346939,\n",
            "    'true_positives': 29},\n",
            "  Mystery, Thriller & Suspense: {   'accuracy': 0.9433222200431457,\n",
            "    'f1_score': 0.12158054711246201,\n",
            "    'fall_out': 0.030069859269008847,\n",
            "    'false_discovery_rate': 0.8813056379821959,\n",
            "    'false_negative_rate': 0.8753894080996885,\n",
            "    'false_negatives': 281,\n",
            "    'false_omission_rate': 0.028496095730656146,\n",
            "    'false_positive_rate': 0.030069859269008847,\n",
            "    'false_positives': 297,\n",
            "    'hit_rate': 0.12461059190031153,\n",
            "    'informedness': 0.09454073263130258,\n",
            "    'markedness': 0.09019826628714811,\n",
            "    'matthews_correlation_coefficient': 0.09234397748018172,\n",
            "    'miss_rate': 0.8753894080996885,\n",
            "    'negative_predictive_value': 0.9715039042693439,\n",
            "    'positive_predictive_value': 0.11869436201780416,\n",
            "    'precision': 0.11869436201780416,\n",
            "    'recall': 0.12461059190031153,\n",
            "    'sensitivity': 0.12461059190031153,\n",
            "    'specificity': 0.9699301407309912,\n",
            "    'true_negative_rate': 0.9699301407309912,\n",
            "    'true_negatives': 9580,\n",
            "    'true_positive_rate': 0.12461059190031153,\n",
            "    'true_positives': 40},\n",
            "  Biographies & Memoirs: {   'accuracy': 0.8951755246126691,\n",
            "    'f1_score': 0.09329940627650551,\n",
            "    'fall_out': 0.03210666666666662,\n",
            "    'false_discovery_rate': 0.8455056179775281,\n",
            "    'false_negative_rate': 0.9331713244228432,\n",
            "    'false_negatives': 768,\n",
            "    'false_omission_rate': 0.0780329201381833,\n",
            "    'false_positive_rate': 0.03210666666666662,\n",
            "    'false_positives': 301,\n",
            "    'hit_rate': 0.06682867557715674,\n",
            "    'informedness': 0.03472200891049004,\n",
            "    'markedness': 0.0764614618842887,\n",
            "    'matthews_correlation_coefficient': 0.05152567865497131,\n",
            "    'miss_rate': 0.9331713244228432,\n",
            "    'negative_predictive_value': 0.9219670798618167,\n",
            "    'positive_predictive_value': 0.1544943820224719,\n",
            "    'precision': 0.1544943820224719,\n",
            "    'recall': 0.06682867557715674,\n",
            "    'sensitivity': 0.06682867557715674,\n",
            "    'specificity': 0.9678933333333334,\n",
            "    'true_negative_rate': 0.9678933333333334,\n",
            "    'true_negatives': 9074,\n",
            "    'true_positive_rate': 0.06682867557715674,\n",
            "    'true_positives': 55}}\n",
            "\n",
            "Finished: experiment_run\n",
            "Saved to: results/experiment_run_0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "21q0EGuO5dpd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "0ExRA9v55cr6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ggjuE4es7SDH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## GCP AutoML\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "ydR9SXDKAXvk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![GCP AutoML](https://user-images.githubusercontent.com/58792/45260264-134c4800-b397-11e8-9832-fd56a8eeaa3c.png)\n",
        "\n",
        "\n",
        "**[GCP AutoML Products](https://cloud.google.com/automl/)**\n",
        "\n",
        "*  [AutoML Vision](https://cloud.google.com/vision/automl/docs/)\n",
        "*  [AutoML Natural Language](https://cloud.google.com/natural-language/automl/docs/)\n",
        "*  [AutoML Translation](https://cloud.google.com/translate/automl/docs/)\n"
      ]
    },
    {
      "metadata": {
        "id": "QYU7DysIifKH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### GCP AutoML Demo\n"
      ]
    },
    {
      "metadata": {
        "id": "MAtZVZgRin7e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Training to recognize flowers\n",
        "\n",
        "![upload_data](https://user-images.githubusercontent.com/58792/45438280-94dbf880-b66b-11e8-850d-e7d2a32c45c8.png)\n",
        "\n",
        "![train](https://user-images.githubusercontent.com/58792/45438281-94dbf880-b66b-11e8-9951-80202c581b0c.png)\n",
        "\n",
        "![predict](https://user-images.githubusercontent.com/58792/45439236-1fbdf280-b66e-11e8-9f51-d92d26a63c64.png)"
      ]
    },
    {
      "metadata": {
        "id": "tBbAdZspTRGW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## References\n"
      ]
    },
    {
      "metadata": {
        "id": "PjOc_DzTTU8v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   [Google Machine Learning Crash Course](https://developers.google.com/machine-learning/crash-course/)\n",
        "*   List item\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "AiFKjr0FTaDC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}